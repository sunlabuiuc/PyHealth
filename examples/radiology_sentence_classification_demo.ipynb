{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzLFFNEJS+RiEPQ5c2olcR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielWarner/PyHealth/blob/mimic-cxr-sentence-example/examples/radiology_sentence_classification_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pyhealth\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from pyhealth.tokenizer import Tokenizer\n",
        "from pyhealth.metrics import multiclass_metrics_fn\n"
      ],
      "metadata": {
        "id": "3GHgu62LA2kg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "046db92b-090f-409f-dec8-46a61bcbae28"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyhealth in /usr/local/lib/python3.12/dist-packages (2.0a8)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (from pyhealth) (1.12.0)\n",
            "Requirement already satisfied: mne~=1.10.0 in /usr/local/lib/python3.12/dist-packages (from pyhealth) (1.10.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pyhealth) (3.6)\n",
            "Requirement already satisfied: numpy~=1.26.4 in /usr/local/lib/python3.12/dist-packages (from pyhealth) (1.26.4)\n",
            "Requirement already satisfied: ogb>=1.3.5 in /usr/local/lib/python3.12/dist-packages (from pyhealth) (1.3.6)\n",
            "Requirement already satisfied: pandarallel~=1.6.5 in /usr/local/lib/python3.12/dist-packages (from pyhealth) (1.6.5)\n",
            "Requirement already satisfied: pandas~=2.3.1 in /usr/local/lib/python3.12/dist-packages (from pyhealth) (2.3.3)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (from pyhealth) (0.18.0)\n",
            "Requirement already satisfied: polars~=1.31.0 in /usr/local/lib/python3.12/dist-packages (from pyhealth) (1.31.0)\n",
            "Requirement already satisfied: pydantic~=2.11.7 in /usr/local/lib/python3.12/dist-packages (from pyhealth) (2.11.10)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.12/dist-packages (from pyhealth) (2025.9.3)\n",
            "Requirement already satisfied: scikit-learn~=1.7.0 in /usr/local/lib/python3.12/dist-packages (from pyhealth) (1.7.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from pyhealth) (0.22.1)\n",
            "Requirement already satisfied: torch~=2.7.1 in /usr/local/lib/python3.12/dist-packages (from pyhealth) (2.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from pyhealth) (4.67.1)\n",
            "Requirement already satisfied: transformers~=4.53.2 in /usr/local/lib/python3.12/dist-packages (from pyhealth) (4.53.3)\n",
            "Requirement already satisfied: urllib3~=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pyhealth) (2.5.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne~=1.10.0->pyhealth) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne~=1.10.0->pyhealth) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne~=1.10.0->pyhealth) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne~=1.10.0->pyhealth) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne~=1.10.0->pyhealth) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne~=1.10.0->pyhealth) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne~=1.10.0->pyhealth) (1.16.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from ogb>=1.3.5->pyhealth) (1.17.0)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ogb>=1.3.5->pyhealth) (0.2.2)\n",
            "Requirement already satisfied: dill>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from pandarallel~=1.6.5->pyhealth) (0.3.8)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from pandarallel~=1.6.5->pyhealth) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas~=2.3.1->pyhealth) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas~=2.3.1->pyhealth) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas~=2.3.1->pyhealth) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic~=2.11.7->pyhealth) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic~=2.11.7->pyhealth) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic~=2.11.7->pyhealth) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic~=2.11.7->pyhealth) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn~=1.7.0->pyhealth) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn~=1.7.0->pyhealth) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch~=2.7.1->pyhealth) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch~=2.7.1->pyhealth) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch~=2.7.1->pyhealth) (1.14.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch~=2.7.1->pyhealth) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch~=2.7.1->pyhealth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch~=2.7.1->pyhealth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch~=2.7.1->pyhealth) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.12/dist-packages (from torch~=2.7.1->pyhealth) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch~=2.7.1->pyhealth) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch~=2.7.1->pyhealth) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch~=2.7.1->pyhealth) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch~=2.7.1->pyhealth) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch~=2.7.1->pyhealth) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.12/dist-packages (from torch~=2.7.1->pyhealth) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.12/dist-packages (from torch~=2.7.1->pyhealth) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch~=2.7.1->pyhealth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch~=2.7.1->pyhealth) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch~=2.7.1->pyhealth) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.12/dist-packages (from torch~=2.7.1->pyhealth) (3.3.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from transformers~=4.53.2->pyhealth) (0.36.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers~=4.53.2->pyhealth) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers~=4.53.2->pyhealth) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers~=4.53.2->pyhealth) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers~=4.53.2->pyhealth) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers~=4.53.2->pyhealth) (0.7.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit->pyhealth) (11.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers~=4.53.2->pyhealth) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne~=1.10.0->pyhealth) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne~=1.10.0->pyhealth) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne~=1.10.0->pyhealth) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne~=1.10.0->pyhealth) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne~=1.10.0->pyhealth) (3.2.5)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.12/dist-packages (from outdated>=0.2.0->ogb>=1.3.5->pyhealth) (0.2.4)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne~=1.10.0->pyhealth) (4.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers~=4.53.2->pyhealth) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers~=4.53.2->pyhealth) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers~=4.53.2->pyhealth) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch~=2.7.1->pyhealth) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne~=1.10.0->pyhealth) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a fixed random seed for reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n"
      ],
      "metadata": {
        "id": "u6pvCuMiA4vf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0042ce0-3bfd-400e-c2f7-02e9287be08d"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "radiology_samples = [\n",
        "    # normal\n",
        "    (\"Lungs are clear. No acute cardiopulmonary abnormality.\", \"normal\"),\n",
        "    (\"No focal consolidation, pleural effusion, or pneumothorax.\", \"normal\"),\n",
        "    (\"Cardiomediastinal silhouette is within normal limits.\", \"normal\"),\n",
        "\n",
        "    # abnormal\n",
        "    (\"Left lower lobe opacity consistent with pneumonia.\", \"abnormal\"),\n",
        "    (\"Moderate right pleural effusion with associated atelectasis.\", \"abnormal\"),\n",
        "    (\"Patchy bilateral ground-glass opacities concerning for infection.\", \"abnormal\"),\n",
        "\n",
        "    # uncertain\n",
        "    (\"Findings could represent early interstitial edema.\", \"uncertain\"),\n",
        "    (\"Cannot exclude a small left apical pneumothorax.\", \"uncertain\"),\n",
        "    (\"Opacity may represent atelectasis versus consolidation.\", \"uncertain\"),\n",
        "]\n",
        "\n",
        "label2id = {\"normal\": 0, \"abnormal\": 1, \"uncertain\": 2}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "texts = [s for s, _ in radiology_samples]\n",
        "labels = [label2id[y] for _, y in radiology_samples]\n",
        "\n",
        "list(zip(texts, labels))\n"
      ],
      "metadata": {
        "id": "9fUGVeJnA6TO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "288f7ad7-4d95-4da7-96d2-b8c97e49761f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Lungs are clear. No acute cardiopulmonary abnormality.', 0),\n",
              " ('No focal consolidation, pleural effusion, or pneumothorax.', 0),\n",
              " ('Cardiomediastinal silhouette is within normal limits.', 0),\n",
              " ('Left lower lobe opacity consistent with pneumonia.', 1),\n",
              " ('Moderate right pleural effusion with associated atelectasis.', 1),\n",
              " ('Patchy bilateral ground-glass opacities concerning for infection.', 1),\n",
              " ('Findings could represent early interstitial edema.', 2),\n",
              " ('Cannot exclude a small left apical pneumothorax.', 2),\n",
              " ('Opacity may represent atelectasis versus consolidation.', 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_tokenize(text: str) -> List[str]:\n",
        "    # very simple whitespace + punctuation handling\n",
        "    text = text.lower().replace(\".\", \"\").replace(\",\", \"\")\n",
        "    return text.split()\n",
        "\n",
        "# Build token space from our tiny corpus\n",
        "token_space = sorted({tok for txt in texts for tok in simple_tokenize(txt)})\n",
        "\n",
        "token_space\n"
      ],
      "metadata": {
        "id": "RYnAxo84BOta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0244d385-eb25-4740-a91d-e85dc98c31d9"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'abnormality',\n",
              " 'acute',\n",
              " 'apical',\n",
              " 'are',\n",
              " 'associated',\n",
              " 'atelectasis',\n",
              " 'bilateral',\n",
              " 'cannot',\n",
              " 'cardiomediastinal',\n",
              " 'cardiopulmonary',\n",
              " 'clear',\n",
              " 'concerning',\n",
              " 'consistent',\n",
              " 'consolidation',\n",
              " 'could',\n",
              " 'early',\n",
              " 'edema',\n",
              " 'effusion',\n",
              " 'exclude',\n",
              " 'findings',\n",
              " 'focal',\n",
              " 'for',\n",
              " 'ground-glass',\n",
              " 'infection',\n",
              " 'interstitial',\n",
              " 'is',\n",
              " 'left',\n",
              " 'limits',\n",
              " 'lobe',\n",
              " 'lower',\n",
              " 'lungs',\n",
              " 'may',\n",
              " 'moderate',\n",
              " 'no',\n",
              " 'normal',\n",
              " 'opacities',\n",
              " 'opacity',\n",
              " 'or',\n",
              " 'patchy',\n",
              " 'pleural',\n",
              " 'pneumonia',\n",
              " 'pneumothorax',\n",
              " 'represent',\n",
              " 'right',\n",
              " 'silhouette',\n",
              " 'small',\n",
              " 'versus',\n",
              " 'with',\n",
              " 'within']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(tokens=token_space, special_tokens=[\"<pad>\", \"<unk>\"])\n",
        "\n",
        "vocab_size = tokenizer.get_vocabulary_size()\n",
        "pad_index = tokenizer.get_padding_index()\n",
        "\n",
        "vocab_size, pad_index\n"
      ],
      "metadata": {
        "id": "rKn3kNEyBT1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c471491-89d7-475a-d82e-8397658e2f16"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 32\n",
        "\n",
        "\n",
        "class RadiologySentenceDataset(Dataset):\n",
        "    \"\"\"Tiny radiology sentence-level dataset using PyHealth Tokenizer.\n",
        "\n",
        "    Each sample returns:\n",
        "      - input_ids: LongTensor of token indices (fixed length MAX_LENGTH)\n",
        "      - label: LongTensor scalar (0=normal,1=abnormal,2=uncertain)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, texts: List[str], labels: List[int], tokenizer: Tokenizer):\n",
        "        assert len(texts) == len(labels)\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.pad_index = tokenizer.get_padding_index()\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        tokens = simple_tokenize(text)\n",
        "\n",
        "        indices_2d = self.tokenizer.batch_encode_2d(batch=[tokens])\n",
        "        indices = list(indices_2d[0])\n",
        "\n",
        "        if len(indices) > MAX_LENGTH:\n",
        "            indices = indices[:MAX_LENGTH]\n",
        "        else:\n",
        "            indices = indices + [self.pad_index] * (MAX_LENGTH - len(indices))\n",
        "\n",
        "        input_ids = torch.tensor(indices, dtype=torch.long)\n",
        "\n",
        "        return input_ids, torch.tensor(label, dtype=torch.long)\n",
        "\n"
      ],
      "metadata": {
        "id": "4R7iWJaoBVPK"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts = texts[:6], texts[6:]\n",
        "train_labels, val_labels = labels[:6], labels[6:]\n",
        "\n",
        "train_dataset = RadiologySentenceDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = RadiologySentenceDataset(val_texts, val_labels, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=3, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=3, shuffle=False)\n",
        "\n",
        "len(train_dataset), len(val_dataset)\n"
      ],
      "metadata": {
        "id": "Yth4SqORBWq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78cdab12-a4ee-4e48-923f-8a4d0106d24c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class ModelConfig:\n",
        "    vocab_size: int\n",
        "    embed_dim: int = 32\n",
        "    num_classes: int = 3\n",
        "    pad_index: int = 0\n",
        "\n",
        "\n",
        "class SimpleTextClassifier(nn.Module):\n",
        "    \"\"\"Minimal text classifier to pair with PyHealth Tokenizer.\"\"\"\n",
        "\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=config.vocab_size,\n",
        "            embedding_dim=config.embed_dim,\n",
        "            padding_idx=config.pad_index,\n",
        "        )\n",
        "        self.fc = nn.Linear(config.embed_dim, config.num_classes)\n",
        "\n",
        "    def forward(self, input_ids: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_ids: [batch_size, seq_len] LongTensor\n",
        "\n",
        "        Returns:\n",
        "            logits: [batch_size, num_classes]\n",
        "        \"\"\"\n",
        "        embedded = self.embedding(input_ids)  # [B, L, D]\n",
        "        # simple average pooling over non-pad positions\n",
        "        mask = (input_ids != pad_index).unsqueeze(-1)  # [B, L, 1]\n",
        "        summed = (embedded * mask).sum(dim=1)\n",
        "        denom = mask.sum(dim=1).clamp(min=1)\n",
        "        pooled = summed / denom\n",
        "        logits = self.fc(pooled)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "tTHwuonjBXjm"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = ModelConfig(\n",
        "    vocab_size=vocab_size,\n",
        "    embed_dim=32,\n",
        "    num_classes=len(label2id),\n",
        "    pad_index=pad_index,\n",
        ")\n",
        "\n",
        "model = SimpleTextClassifier(config).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "model\n"
      ],
      "metadata": {
        "id": "Z2vs-lm1BZU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ad7b19c-8d3e-4c96-cebe-3ac868718437"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleTextClassifier(\n",
              "  (embedding): Embedding(52, 32, padding_idx=0)\n",
              "  (fc): Linear(in_features=32, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_epoch(loader: DataLoader, train: bool = True):\n",
        "    if train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "    all_labels = []\n",
        "\n",
        "    total_loss = 0.0\n",
        "    count = 0\n",
        "\n",
        "    for input_ids, labels_batch in loader:\n",
        "        input_ids = input_ids.to(device)\n",
        "        labels_batch = labels_batch.to(device)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(train):\n",
        "            logits = model(input_ids)\n",
        "            loss = criterion(logits, labels_batch)\n",
        "\n",
        "            if train:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        batch_size = labels_batch.size(0)\n",
        "        total_loss += loss.item() * batch_size\n",
        "        count += batch_size\n",
        "\n",
        "        all_logits.append(logits.detach().cpu())\n",
        "        all_labels.append(labels_batch.detach().cpu())\n",
        "\n",
        "    avg_loss = total_loss / max(count, 1)\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "    all_labels = torch.cat(all_labels, dim=0)\n",
        "\n",
        "    return avg_loss, all_logits, all_labels\n"
      ],
      "metadata": {
        "id": "ZcBwi0QpBakY"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss, _, _ = run_epoch(train_loader, train=True)\n",
        "    val_loss, val_logits, val_labels = run_epoch(val_loader, train=False)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} | val_loss={val_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "A6G_mmIwBbsg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8863485c-dff2-48a6-acbf-84e181df0350"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | train_loss=1.1041 | val_loss=1.1970\n",
            "Epoch 02 | train_loss=1.0899 | val_loss=1.2033\n",
            "Epoch 03 | train_loss=1.0770 | val_loss=1.2102\n",
            "Epoch 04 | train_loss=1.0650 | val_loss=1.2160\n",
            "Epoch 05 | train_loss=1.0532 | val_loss=1.2218\n",
            "Epoch 06 | train_loss=1.0419 | val_loss=1.2276\n",
            "Epoch 07 | train_loss=1.0303 | val_loss=1.2331\n",
            "Epoch 08 | train_loss=1.0190 | val_loss=1.2388\n",
            "Epoch 09 | train_loss=1.0078 | val_loss=1.2443\n",
            "Epoch 10 | train_loss=0.9967 | val_loss=1.2498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "_, train_logits, train_labels_tensor = run_epoch(train_loader, train=False)\n",
        "_, val_logits, val_labels_tensor = run_epoch(val_loader, train=False)\n",
        "\n",
        "y_true = np.concatenate(\n",
        "    [train_labels_tensor.numpy(), val_labels_tensor.numpy()], axis=0\n",
        ")\n",
        "\n",
        "y_prob = torch.softmax(\n",
        "    torch.cat([train_logits, val_logits], dim=0), dim=-1\n",
        ").numpy()\n",
        "\n",
        "metrics = multiclass_metrics_fn(\n",
        "    y_true=y_true,\n",
        "    y_prob=y_prob,\n",
        "    metrics=[\"accuracy\", \"f1_macro\"],\n",
        ")\n",
        "\n",
        "metrics\n"
      ],
      "metadata": {
        "id": "hUocx1k_Bcgx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d36bdc6-aeaa-4490-b7d5-2f4f24e06ee8"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.5555555555555556, 'f1_macro': 0.5222222222222221}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    }
  ]
}