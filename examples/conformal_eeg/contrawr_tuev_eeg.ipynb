{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc0cd8e1",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "Seed RNGs, import dependencies, and choose a device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "186e32d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5961110",
   "metadata": {},
   "source": [
    "## 2. Load TUEV Dataset\n",
    "Point `root` to the `edf/` directory of TUEV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed7e4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No config path provided, using default config\n",
      "Using both train and eval subsets\n",
      "Initializing tuev dataset from ../../downloads/tuev/v2.0.1/edf (dev mode: False)\n",
      "No cache_dir provided. Using default cache dir: C:\\Users\\Razin\\AppData\\Local\\pyhealth\\pyhealth\\Cache\\743c627e-3664-5ebd-aa5c-dbbe789f5e83\n",
      "Dataset: tuev\n",
      "Dev mode: False\n",
      "Number of patients: 4\n",
      "Number of events: 4\n"
     ]
    }
   ],
   "source": [
    "from pyhealth.datasets import TUEVDataset\n",
    "\n",
    "# Example relative path (from this notebook's folder):\n",
    "#   <repo_root>/downloads/tuev/v2.0.1/edf\n",
    "# Update as needed.\n",
    "dataset = TUEVDataset(\n",
    "    root=\"../../downloads/tuev/v2.0.1/edf\",\n",
    "    subset=\"both\",  # 'train', 'eval', or 'both'\n",
    ")\n",
    "dataset.stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3ac3ac",
   "metadata": {},
   "source": [
    "## 3. Prepare Task Dataset\n",
    "Apply the `EEGEventsTUEV` task to produce one sample per annotated event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13115d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting task EEG_events for tuev base dataset...\n",
      "Applying task transformations on data with 1 workers...\n",
      "Detected Jupyter notebook environment, setting num_workers to 1\n",
      "Single worker mode, processing sequentially\n",
      "Worker 0 started processing 4 patients. (Polars threads: 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 inferred the following `['bytes']` data format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:21<00:00,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 0 finished processing patients.\n",
      "Fitting processors on the dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label label vocab: {0: 0, 3: 1, 4: 2, 5: 3}\n",
      "Processing samples and saving to C:\\Users\\Razin\\AppData\\Local\\pyhealth\\pyhealth\\Cache\\743c627e-3664-5ebd-aa5c-dbbe789f5e83\\tasks\\EEG_events\\samples_896eeb17-2673-41d9-b878-99d335df68c4.ld...\n",
      "Applying processors on data with 1 workers...\n",
      "Detected Jupyter notebook environment, setting num_workers to 1\n",
      "Single worker mode, processing sequentially\n",
      "Worker 0 started processing 1395 samples. (0 to 1395)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1395 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 inferred the following `['str', 'pickle', 'tensor', 'int', 'tensor']` data format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1395/1395 [00:01<00:00, 1363.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 0 finished processing samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached processed samples to C:\\Users\\Razin\\AppData\\Local\\pyhealth\\pyhealth\\Cache\\743c627e-3664-5ebd-aa5c-dbbe789f5e83\\tasks\\EEG_events\\samples_896eeb17-2673-41d9-b878-99d335df68c4.ld\n",
      "Total task samples: 1395\n",
      "Input schema: {'signal': 'tensor'}\n",
      "Output schema: {'label': 'multiclass'}\n",
      "\n",
      "Sample keys: dict_keys(['patient_id', 'signal_file', 'signal', 'offending_channel', 'label'])\n",
      "Signal shape: torch.Size([16, 1280])\n",
      "Label: 3\n"
     ]
    }
   ],
   "source": [
    "from pyhealth.tasks import EEGEventsTUEV\n",
    "\n",
    "sample_dataset = dataset.set_task(EEGEventsTUEV())\n",
    "\n",
    "print(f\"Total task samples: {len(sample_dataset)}\")\n",
    "print(f\"Input schema: {sample_dataset.input_schema}\")\n",
    "print(f\"Output schema: {sample_dataset.output_schema}\")\n",
    "\n",
    "if len(sample_dataset) == 0:\n",
    "    raise RuntimeError(\"The task did not produce any samples. Verify the dataset root.\")\n",
    "\n",
    "sample = sample_dataset[0]\n",
    "print(f\"\\nSample keys: {sample.keys()}\")\n",
    "print(f\"Signal shape: {sample['signal'].shape}\")\n",
    "print(f\"Label: {sample['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4568d5",
   "metadata": {},
   "source": [
    "## 4. Split Dataset\n",
    "Split into train/val/test and build dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ac3eacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test sizes: 976, 140, 279\n"
     ]
    }
   ],
   "source": [
    "from pyhealth.datasets.splitter import split_by_sample\n",
    "from pyhealth.datasets.utils import get_dataloader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_ds, val_ds, test_ds = split_by_sample(sample_dataset, [0.7, 0.1, 0.2], seed=SEED)\n",
    "print(f\"Train/Val/Test sizes: {len(train_ds)}, {len(val_ds)}, {len(test_ds)}\")\n",
    "\n",
    "train_loader = get_dataloader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = get_dataloader(val_ds, batch_size=BATCH_SIZE) if len(val_ds) else None\n",
    "test_loader = get_dataloader(test_ds, batch_size=BATCH_SIZE) if len(test_ds) else None\n",
    "\n",
    "if len(train_loader) == 0:\n",
    "    raise RuntimeError(\"The training loader is empty. Increase the dataset size or adjust the split ratios.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6163efad",
   "metadata": {},
   "source": [
    "## 5. Inspect Batch Structure\n",
    "Check the first batch to confirm shapes match what `ContraWR` expects: `(batch, channels, length)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "401fbf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch structure:\n",
      "  patient_id: list(len=32)\n",
      "  signal_file: list(len=32)\n",
      "  signal: Tensor(shape=(32, 16, 1280))\n",
      "  offending_channel: list(len=32)\n",
      "  label: Tensor(shape=(32,))\n"
     ]
    }
   ],
   "source": [
    "first_batch = next(iter(train_loader))\n",
    "\n",
    "def describe(value):\n",
    "    if hasattr(value, 'shape'):\n",
    "        return f\"{type(value).__name__}(shape={tuple(value.shape)})\"\n",
    "    if isinstance(value, (list, tuple)):\n",
    "        return f\"{type(value).__name__}(len={len(value)})\"\n",
    "    return type(value).__name__\n",
    "\n",
    "print('Batch structure:')\n",
    "for key, value in first_batch.items():\n",
    "    print(f\"  {key}: {describe(value)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8be3c4",
   "metadata": {},
   "source": [
    "## 6. Instantiate ContraWR\n",
    "Create the `ContraWR` model using the task dataset (it infers feature/label keys from the dataset schema)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7225d430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Input data dimensions ===\n",
      "n_channels: 16\n",
      "length: 1280\n",
      "=== Spectrogram parameters ===\n",
      "n_channels: 16\n",
      "freq_dim: 65\n",
      "time_steps: 37\n",
      "=== Convolution Parameters ===\n",
      "in_channels: 16, out_channels: 32, freq_dim: 16, time_steps: 9\n",
      "in_channels: 32, out_channels: 64, freq_dim: 4, time_steps: 2\n",
      "\n",
      "Feature keys: ['signal']\n",
      "Label key: ['label']\n",
      "Model mode: multiclass\n",
      "Total parameters: 95,076\n",
      "Trainable parameters: 95,076\n"
     ]
    }
   ],
   "source": [
    "from pyhealth.models import ContraWR\n",
    "\n",
    "model = ContraWR(\n",
    "    dataset=sample_dataset,\n",
    "    n_fft=128,\n",
    ").to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Feature keys: {model.feature_keys}\")\n",
    "print(f\"Label key: {model.label_keys}\")\n",
    "print(f\"Model mode: {model.mode}\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5353f727",
   "metadata": {},
   "source": [
    "## 7. Test Forward Pass\n",
    "Run a no-grad forward pass and verify the loss/outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d095b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output keys: dict_keys(['loss', 'y_prob', 'y_true', 'logit'])\n",
      "Loss: 46.9889\n",
      "y_prob shape: (32, 4)\n",
      "y_true shape: (32,)\n"
     ]
    }
   ],
   "source": [
    "test_batch = {\n",
    "    key: (value.to(device) if hasattr(value, 'to') else value)\n",
    "    for key, value in first_batch.items()\n",
    "}\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(**test_batch)\n",
    "\n",
    "print('Model output keys:', output.keys())\n",
    "print(f\"Loss: {output['loss'].item():.4f}\")\n",
    "print(f\"y_prob shape: {tuple(output['y_prob'].shape)}\")\n",
    "print(f\"y_true shape: {tuple(output['y_true'].shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714a3fef",
   "metadata": {},
   "source": [
    "## 8. Train with PyHealth Trainer\n",
    "Train `ContraWR` on the TUEV EEG events task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14a7233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContraWR(\n",
      "  (encoder): Sequential(\n",
      "    (0): ResBlock2D(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ELU(alpha=1.0)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (downsampler): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (1): ResBlock2D(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ELU(alpha=1.0)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (downsampler): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyhealth.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    device=str(device),\n",
    "    enable_logging=False,\n",
    ")\n",
    "\n",
    "training_config = {\n",
    "    'epochs': 10,\n",
    "    'optimizer_params': {'lr': 1e-3},\n",
    "    'max_grad_norm': 5.0,\n",
    "    # 'monitor': 'accuracy',  # uncomment to track a metric on val\n",
    "    # 'monitor_criterion': 'max',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de6f54ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.adam.Adam'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: 5.0\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000024B1631A0E0>\n",
      "Monitor: None\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "Patience: None\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d6d215b9bf4cd7a51af7452399c78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0 / 10:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-31 ---\n",
      "loss: 0.6033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00, 22.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-0, step-31 ---\n",
      "accuracy: 0.8857\n",
      "f1_macro: 0.4340\n",
      "f1_micro: 0.8857\n",
      "loss: 0.3663\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d18cbe7a76a466294e86ceb2d7f8f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 / 10:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-62 ---\n",
      "loss: 0.4586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00, 22.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-1, step-62 ---\n",
      "accuracy: 0.9286\n",
      "f1_macro: 0.8295\n",
      "f1_micro: 0.9286\n",
      "loss: 0.2543\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9105b3cad2b4d068a8efad6dbbdd1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 / 10:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-93 ---\n",
      "loss: 0.3077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00, 24.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-2, step-93 ---\n",
      "accuracy: 0.9214\n",
      "f1_macro: 0.8957\n",
      "f1_micro: 0.9214\n",
      "loss: 0.2323\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdafb4ea627843bcaaac3f2ff3cdd983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 / 10:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-124 ---\n",
      "loss: 0.2483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00, 25.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-3, step-124 ---\n",
      "accuracy: 0.9214\n",
      "f1_macro: 0.9086\n",
      "f1_micro: 0.9214\n",
      "loss: 0.1891\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7aae28574044cdb0b3b2b48fe5d354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 / 10:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-155 ---\n",
      "loss: 0.1782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00, 22.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-4, step-155 ---\n",
      "accuracy: 0.9286\n",
      "f1_macro: 0.9144\n",
      "f1_micro: 0.9286\n",
      "loss: 0.1460\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36f26a6bc6e4021b53a4ba4334079d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 / 10:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-186 ---\n",
      "loss: 0.1769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00, 24.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-5, step-186 ---\n",
      "accuracy: 0.9214\n",
      "f1_macro: 0.8957\n",
      "f1_micro: 0.9214\n",
      "loss: 0.1793\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2995b89a7d4c3498b2a21bcea6c400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 / 10:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-217 ---\n",
      "loss: 0.1239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00, 24.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-6, step-217 ---\n",
      "accuracy: 0.9714\n",
      "f1_macro: 0.9808\n",
      "f1_micro: 0.9714\n",
      "loss: 0.1368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8bcd7ae1a234f4f9c886d8d465f8e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 / 10:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-248 ---\n",
      "loss: 0.1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00, 24.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-7, step-248 ---\n",
      "accuracy: 0.9714\n",
      "f1_macro: 0.9808\n",
      "f1_micro: 0.9714\n",
      "loss: 0.0995\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db14e66dd4844765be006088cca8abaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 / 10:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-279 ---\n",
      "loss: 0.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00, 24.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-8, step-279 ---\n",
      "accuracy: 0.9714\n",
      "f1_macro: 0.9808\n",
      "f1_micro: 0.9714\n",
      "loss: 0.1059\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77f8c0ba8694105ac81e276d975fc7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 / 10:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-310 ---\n",
      "loss: 0.1139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00, 24.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-9, step-310 ---\n",
      "accuracy: 0.9786\n",
      "f1_macro: 0.8637\n",
      "f1_micro: 0.9786\n",
      "loss: 0.0581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "    train_dataloader=train_loader,\n",
    "    val_dataloader=val_loader,\n",
    "    **training_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84033f69",
   "metadata": {},
   "source": [
    "## 9. Evaluate on Test Set\n",
    "Compute multiclass metrics on the held-out test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77ecc3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 9/9 [00:00<00:00, 19.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test scores:\n",
      "  accuracy: 0.9749\n",
      "  f1_macro: 0.9491\n",
      "  f1_micro: 0.9749\n",
      "  loss: 0.0824\n"
     ]
    }
   ],
   "source": [
    "if test_loader is None:\n",
    "    raise RuntimeError('No test dataloader was created.')\n",
    "\n",
    "scores = trainer.evaluate(test_loader)\n",
    "print('Test scores:')\n",
    "for k, v in scores.items():\n",
    "    print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc39abe",
   "metadata": {},
   "source": [
    "## 10. Save Model (Optional)\n",
    "Save the trained weights to a checkpoint file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3882fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: contrawr_tuev_model.pth\n"
     ]
    }
   ],
   "source": [
    "save_path = 'contrawr_tuev_model.pth'\n",
    "torch.save(\n",
    "    {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'config': training_config,\n",
    "    },\n",
    "    save_path,\n",
    ")\n",
    "print(f\"Model saved to: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
