{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: Mortality Prediction on MIMIC-III (Baseline â€” No code_mapping)\n",
    "\n",
    "This notebook runs the RNN model for mortality prediction **without** `code_mapping`.\n",
    "Raw ICD-9 and NDC codes are used as-is for the embedding vocabulary.\n",
    "\n",
    "**Model:** RNN (GRU)  \n",
    "**Task:** In-hospital mortality prediction  \n",
    "**Dataset:** Synthetic MIMIC-III (`dev=False`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the MIMIC-III Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "from pyhealth.datasets import MIMIC3Dataset\n",
    "\n",
    "base_dataset = MIMIC3Dataset(\n",
    "    root=\"https://storage.googleapis.com/pyhealth/Synthetic_MIMIC-III\",\n",
    "    tables=[\"DIAGNOSES_ICD\", \"PROCEDURES_ICD\", \"PRESCRIPTIONS\"],\n",
    "    cache_dir=tempfile.TemporaryDirectory().name,\n",
    "    dev=False,\n",
    ")\n",
    "\n",
    "base_dataset.stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the Mortality Prediction Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.tasks import MortalityPredictionMIMIC3\n",
    "\n",
    "task = MortalityPredictionMIMIC3()\n",
    "\n",
    "samples = base_dataset.set_task(task)\n",
    "\n",
    "print(f\"Generated {len(samples)} samples\")\n",
    "print(f\"\\nInput schema: {samples.input_schema}\")\n",
    "print(f\"Output schema: {samples.output_schema}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample structure:\")\n",
    "print(samples[0])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Processor Vocabulary Sizes:\")\n",
    "print(\"=\" * 50)\n",
    "for key, proc in samples.input_processors.items():\n",
    "    if hasattr(proc, 'code_vocab'):\n",
    "        print(f\"{key}: {len(proc.code_vocab)} codes (including <pad>, <unk>)\")\n",
    "\n",
    "mortality_count = sum(float(s.get(\"mortality\", 0)) for s in samples)\n",
    "print(f\"\\nTotal samples: {len(samples)}\")\n",
    "print(f\"Mortality rate: {mortality_count / len(samples) * 100:.2f}%\")\n",
    "print(f\"Positive samples: {int(mortality_count)}\")\n",
    "print(f\"Negative samples: {len(samples) - int(mortality_count)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.datasets import split_by_patient\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = split_by_patient(\n",
    "    samples, [0.8, 0.1, 0.1], seed=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.datasets import get_dataloader\n",
    "\n",
    "train_dataloader = get_dataloader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = get_dataloader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = get_dataloader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Training batches: {len(train_dataloader)}\")\n",
    "print(f\"Validation batches: {len(val_dataloader)}\")\n",
    "print(f\"Test batches: {len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Initialize the RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.models import RNN\n",
    "\n",
    "model = RNN(\n",
    "    dataset=samples,\n",
    "    embedding_dim=128,\n",
    "    hidden_dim=128,\n",
    ")\n",
    "\n",
    "print(f\"Model initialized with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "print(f\"\\nModel architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    metrics=[\"roc_auc\", \"pr_auc\", \"accuracy\", \"f1\"],\n",
    ")\n",
    "\n",
    "trainer.train(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    epochs=50,\n",
    "    monitor=\"roc_auc\",\n",
    "    optimizer_params={\"lr\": 1e-3},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = trainer.evaluate(test_dataloader)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Test Set Performance (NO code_mapping)\")\n",
    "print(\"=\" * 50)\n",
    "for metric, value in test_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}