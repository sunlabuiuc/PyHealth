{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "220bb967",
   "metadata": {},
   "source": [
    "# SHAP Interpretability for StageNet on MIMIC-IV\n",
    "\n",
    "This notebook demonstrates how to use the SHAP (SHapley Additive exPlanations) interpretability method with a StageNet model trained on MIMIC-IV data for mortality prediction.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/naveenkcb/PyHealth/blob/master/examples/shap_stagenet_mimic4.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bac98d",
   "metadata": {},
   "source": [
    "## Setup: Install PyHealth from Your Forked Repository\n",
    "\n",
    "First, we'll install PyHealth directly from your forked GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef5d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyHealth from forked repository\n",
    "!pip install git+https://github.com/naveenkcb/PyHealth.git -q\n",
    "\n",
    "# Install additional required dependencies\n",
    "!pip install polars -q\n",
    "\n",
    "print(\"✓ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adab849",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b920ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import torch\n",
    "\n",
    "from pyhealth.datasets import (\n",
    "    MIMIC4EHRDataset,\n",
    "    get_dataloader,\n",
    "    load_processors,\n",
    "    split_by_patient,\n",
    ")\n",
    "from pyhealth.interpret.methods import ShapExplainer\n",
    "from pyhealth.models import StageNet\n",
    "from pyhealth.tasks import MortalityPredictionStageNetMIMIC4\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bffddf",
   "metadata": {},
   "source": [
    "## Setup MIMIC-IV Dataset Path\n",
    "\n",
    "**Note**: You'll need to:\n",
    "1. Have access to MIMIC-IV dataset (requires PhysioNet credentialing)\n",
    "2. Update the `dataset_root` path below to point to your MIMIC-IV data location\n",
    "3. If running on Colab, you may need to mount Google Drive or upload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62213a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: For local MIMIC-IV data\n",
    "dataset_root = \"/home/logic/physionet.org/files/mimic-iv-demo/2.2/\"\n",
    "\n",
    "# Option 2: For Google Drive (uncomment if using Colab with Drive)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# dataset_root = \"/content/drive/MyDrive/mimic-iv-demo/2.2/\"\n",
    "\n",
    "# Option 3: For demo data (update path as needed)\n",
    "# dataset_root = \"/path/to/your/mimic-iv-demo/\"\n",
    "\n",
    "print(f\"Dataset root: {dataset_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684c26d6",
   "metadata": {},
   "source": [
    "## Load MIMIC-IV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bda0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure dataset location and load cached processors\n",
    "dataset = MIMIC4EHRDataset(\n",
    "    root=dataset_root,\n",
    "    tables=[\n",
    "        \"patients\",\n",
    "        \"admissions\",\n",
    "        \"diagnoses_icd\",\n",
    "        \"procedures_icd\",\n",
    "        \"labevents\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"✓ Dataset loaded with {len(dataset.patients)} patients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a10d6b",
   "metadata": {},
   "source": [
    "## Setup ICD Code Description Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7d9850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_icd_description_map(dataset_root: str) -> dict:\n",
    "    \"\"\"Load ICD code → long title mappings from MIMIC-IV reference tables.\"\"\"\n",
    "    mapping = {}\n",
    "    root_path = Path(dataset_root).expanduser()\n",
    "    diag_path = root_path / \"hosp\" / \"d_icd_diagnoses.csv.gz\"\n",
    "    proc_path = root_path / \"hosp\" / \"d_icd_procedures.csv.gz\"\n",
    "\n",
    "    icd_dtype = {\"icd_code\": pl.Utf8, \"long_title\": pl.Utf8}\n",
    "\n",
    "    if diag_path.exists():\n",
    "        diag_df = pl.read_csv(\n",
    "            diag_path,\n",
    "            columns=[\"icd_code\", \"long_title\"],\n",
    "            dtypes=icd_dtype,\n",
    "        )\n",
    "        mapping.update(\n",
    "            zip(diag_df[\"icd_code\"].to_list(), diag_df[\"long_title\"].to_list())\n",
    "        )\n",
    "\n",
    "    if proc_path.exists():\n",
    "        proc_df = pl.read_csv(\n",
    "            proc_path,\n",
    "            columns=[\"icd_code\", \"long_title\"],\n",
    "            dtypes=icd_dtype,\n",
    "        )\n",
    "        mapping.update(\n",
    "            zip(proc_df[\"icd_code\"].to_list(), proc_df[\"long_title\"].to_list())\n",
    "        )\n",
    "\n",
    "    return mapping\n",
    "\n",
    "\n",
    "ICD_CODE_TO_DESC = load_icd_description_map(dataset.root)\n",
    "print(f\"✓ Loaded {len(ICD_CODE_TO_DESC)} ICD code descriptions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c625121",
   "metadata": {},
   "source": [
    "## Setup Mortality Prediction Task\n",
    "\n",
    "**Note**: You'll need preprocessed data (processors) and a trained model checkpoint. \n",
    "Update the paths below or train a model first using the PyHealth training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a11d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to cached processors (update this path)\n",
    "processors_path = \"../resources/\"\n",
    "\n",
    "# Load or create processors\n",
    "try:\n",
    "    input_processors, output_processors = load_processors(processors_path)\n",
    "    print(\"✓ Loaded cached processors\")\n",
    "except:\n",
    "    print(\"⚠ Could not load processors. Will create new ones.\")\n",
    "    input_processors = None\n",
    "    output_processors = None\n",
    "\n",
    "# Set up the task\n",
    "sample_dataset = dataset.set_task(\n",
    "    MortalityPredictionStageNetMIMIC4(),\n",
    "    cache_dir=\"~/.cache/pyhealth/mimic4_stagenet_mortality\",\n",
    "    input_processors=input_processors,\n",
    "    output_processors=output_processors,\n",
    ")\n",
    "\n",
    "print(f\"✓ Total samples: {len(sample_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d1b31e",
   "metadata": {},
   "source": [
    "## Load Pre-trained StageNet Model\n",
    "\n",
    "**Note**: You need a trained model checkpoint. Update the path below or train a model first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4b7e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "model = StageNet(\n",
    "    dataset=sample_dataset,\n",
    "    embedding_dim=128,\n",
    "    chunk_size=128,\n",
    "    levels=3,\n",
    "    dropout=0.3,\n",
    ")\n",
    "\n",
    "# Load trained weights (update this path)\n",
    "checkpoint_path = \"../resources/best.ckpt\"\n",
    "\n",
    "try:\n",
    "    state_dict = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(\"✓ Loaded pre-trained model\")\n",
    "except:\n",
    "    print(\"⚠ Could not load checkpoint. Using randomly initialized model.\")\n",
    "    print(\"   (Results will not be meaningful without a trained model)\")\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748990ff",
   "metadata": {},
   "source": [
    "## Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f2fb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "_, _, test_data = split_by_patient(sample_dataset, [0.7, 0.1, 0.2], seed=42)\n",
    "test_loader = get_dataloader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "print(f\"✓ Test set: {len(test_data)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b174b1",
   "metadata": {},
   "source": [
    "## Helper Functions for Attribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fe6d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_batch_to_device(batch, target_device):\n",
    "    \"\"\"Move all tensors in batch to target device.\"\"\"\n",
    "    moved = {}\n",
    "    for key, value in batch.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            moved[key] = value.to(target_device)\n",
    "        elif isinstance(value, tuple):\n",
    "            moved[key] = tuple(v.to(target_device) for v in value)\n",
    "        else:\n",
    "            moved[key] = value\n",
    "    return moved\n",
    "\n",
    "\n",
    "LAB_CATEGORY_NAMES = MortalityPredictionStageNetMIMIC4.LAB_CATEGORY_NAMES\n",
    "\n",
    "\n",
    "def decode_token(idx: int, processor, feature_key: str):\n",
    "    \"\"\"Decode token index to human-readable string.\"\"\"\n",
    "    if processor is None or not hasattr(processor, \"code_vocab\"):\n",
    "        return str(idx)\n",
    "    reverse_vocab = {index: token for token, index in processor.code_vocab.items()}\n",
    "    token = reverse_vocab.get(idx, f\"<UNK:{idx}>\")\n",
    "\n",
    "    if feature_key == \"icd_codes\" and token not in {\"<unk>\", \"<pad>\"}:\n",
    "        desc = ICD_CODE_TO_DESC.get(token)\n",
    "        if desc:\n",
    "            return f\"{token}: {desc}\"\n",
    "\n",
    "    return token\n",
    "\n",
    "\n",
    "def unravel(flat_index: int, shape: torch.Size):\n",
    "    \"\"\"Convert flat index to multi-dimensional coordinates.\"\"\"\n",
    "    coords = []\n",
    "    remaining = flat_index\n",
    "    for dim in reversed(shape):\n",
    "        coords.append(remaining % dim)\n",
    "        remaining //= dim\n",
    "    return list(reversed(coords))\n",
    "\n",
    "\n",
    "def print_top_attributions(\n",
    "    attributions,\n",
    "    batch,\n",
    "    processors,\n",
    "    top_k: int = 10,\n",
    "):\n",
    "    \"\"\"Print top-k most important features from SHAP attributions.\"\"\"\n",
    "    for feature_key, attr in attributions.items():\n",
    "        attr_cpu = attr.detach().cpu()\n",
    "        if attr_cpu.dim() == 0 or attr_cpu.size(0) == 0:\n",
    "            continue\n",
    "\n",
    "        feature_input = batch[feature_key]\n",
    "        if isinstance(feature_input, tuple):\n",
    "            feature_input = feature_input[1]\n",
    "        feature_input = feature_input.detach().cpu()\n",
    "\n",
    "        flattened = attr_cpu[0].flatten()\n",
    "        if flattened.numel() == 0:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nFeature: {feature_key}\")\n",
    "        print(f\"  Shape: {attr_cpu[0].shape}\")\n",
    "        print(f\"  Total attribution sum: {flattened.sum().item():+.6f}\")\n",
    "        print(f\"  Mean attribution: {flattened.mean().item():+.6f}\")\n",
    "        \n",
    "        k = min(top_k, flattened.numel())\n",
    "        top_values, top_indices = torch.topk(flattened.abs(), k=k)\n",
    "        processor = processors.get(feature_key) if processors else None\n",
    "        is_continuous = torch.is_floating_point(feature_input)\n",
    "\n",
    "        print(f\"\\n  Top {k} most important features:\")\n",
    "        for rank, (_, flat_idx) in enumerate(zip(top_values, top_indices), 1):\n",
    "            attribution_value = flattened[flat_idx].item()\n",
    "            coords = unravel(flat_idx.item(), attr_cpu[0].shape)\n",
    "\n",
    "            if is_continuous:\n",
    "                actual_value = feature_input[0][tuple(coords)].item()\n",
    "                label = \"\"\n",
    "                if feature_key == \"labs\" and len(coords) >= 1:\n",
    "                    lab_idx = coords[-1]\n",
    "                    if lab_idx < len(LAB_CATEGORY_NAMES):\n",
    "                        label = f\"{LAB_CATEGORY_NAMES[lab_idx]} \"\n",
    "                print(\n",
    "                    f\"    {rank:2d}. idx={coords} {label}value={actual_value:.4f} \"\n",
    "                    f\"SHAP={attribution_value:+.6f}\"\n",
    "                )\n",
    "            else:\n",
    "                token_idx = int(feature_input[0][tuple(coords)].item())\n",
    "                token = decode_token(token_idx, processor, feature_key)\n",
    "                print(\n",
    "                    f\"    {rank:2d}. idx={coords} token='{token}' \"\n",
    "                    f\"SHAP={attribution_value:+.6f}\"\n",
    "                )\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee07463",
   "metadata": {},
   "source": [
    "## Initialize SHAP Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Initializing SHAP Explainer\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize SHAP explainer with custom parameters\n",
    "shap_explainer = ShapExplainer(\n",
    "    model,\n",
    "    use_embeddings=True,  # Use embeddings for discrete features\n",
    "    n_background_samples=50,  # Number of background samples\n",
    "    max_coalitions=200,  # Number of feature coalitions to sample\n",
    "    random_seed=42,  # For reproducibility\n",
    ")\n",
    "\n",
    "print(\"\\nSHAP Configuration:\")\n",
    "print(f\"  Use embeddings: {shap_explainer.use_embeddings}\")\n",
    "print(f\"  Background samples: {shap_explainer.n_background_samples}\")\n",
    "print(f\"  Max coalitions: {shap_explainer.max_coalitions}\")\n",
    "print(f\"  Regularization: {shap_explainer.regularization}\")\n",
    "print(f\"  Random seed: {shap_explainer.random_seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ab806a",
   "metadata": {},
   "source": [
    "## Get Sample and Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f8fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample from test set\n",
    "sample_batch = next(iter(test_loader))\n",
    "sample_batch_device = move_batch_to_device(sample_batch, device)\n",
    "\n",
    "# Get model prediction\n",
    "with torch.no_grad():\n",
    "    output = model(**sample_batch_device)\n",
    "    probs = output[\"y_prob\"]\n",
    "    preds = torch.argmax(probs, dim=-1)\n",
    "    label_key = model.label_key\n",
    "    true_label = sample_batch_device[label_key]\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Model Prediction for Sampled Patient\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"  True label: {int(true_label.item())} {'(Deceased)' if true_label.item() == 1 else '(Survived)'}\")\n",
    "    print(f\"  Predicted class: {int(preds.item())} {'(Deceased)' if preds.item() == 1 else '(Survived)'}\")\n",
    "    print(f\"  Probabilities: [Survive={probs[0][0].item():.4f}, Death={probs[0][1].item():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dc0d56",
   "metadata": {},
   "source": [
    "## Compute SHAP Attributions\n",
    "\n",
    "This cell computes SHAP values for the mortality prediction (class 1). \n",
    "**Note**: This may take 1-2 minutes depending on the number of coalitions and background samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd87e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Computing SHAP Attributions (this may take a minute...)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "attributions = shap_explainer.attribute(**sample_batch_device, target_class_idx=1)\n",
    "\n",
    "print(\"\\n✓ SHAP computation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0157172c",
   "metadata": {},
   "source": [
    "## Display SHAP Attribution Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb5ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SHAP Attribution Results\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nSHAP values explain the contribution of each feature to the model's\")\n",
    "print(\"prediction of MORTALITY (class 1). Positive values increase the\")\n",
    "print(\"mortality prediction, negative values decrease it.\")\n",
    "\n",
    "print_top_attributions(attributions, sample_batch_device, input_processors, top_k=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977162e1",
   "metadata": {},
   "source": [
    "## Compare Different Baseline Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b3565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Testing Different Baseline Strategies\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Automatic baseline (default)\n",
    "print(\"\\n1. Automatic baseline generation:\")\n",
    "attr_auto = shap_explainer.attribute(**sample_batch_device, target_class_idx=1)\n",
    "print(f\"   Total attribution (icd_codes): {attr_auto['icd_codes'][0].sum().item():+.6f}\")\n",
    "\n",
    "# 2. Custom zero baseline\n",
    "print(\"\\n2. Custom zero baseline:\")\n",
    "zero_baseline = {}\n",
    "for key in model.feature_keys:\n",
    "    if key in sample_batch_device:\n",
    "        feature_input = sample_batch_device[key]\n",
    "        if isinstance(feature_input, tuple):\n",
    "            feature_input = feature_input[1]\n",
    "        zero_baseline[key] = torch.zeros(\n",
    "            (shap_explainer.n_background_samples,) + feature_input.shape[1:],\n",
    "            device=device,\n",
    "            dtype=feature_input.dtype\n",
    "        )\n",
    "\n",
    "attr_zero = shap_explainer.attribute(\n",
    "    baseline=zero_baseline,\n",
    "    **sample_batch_device,\n",
    "    target_class_idx=1\n",
    ")\n",
    "print(f\"   Total attribution (icd_codes): {attr_zero['icd_codes'][0].sum().item():+.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d102ed3",
   "metadata": {},
   "source": [
    "## Test Callable Interface\n",
    "\n",
    "Verify that both `explainer.attribute()` and `explainer()` produce identical results when using a random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405c73b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Testing Callable Interface\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Both methods should produce identical results (due to random_seed)\n",
    "attr_from_attribute = shap_explainer.attribute(**sample_batch_device, target_class_idx=1)\n",
    "attr_from_call = shap_explainer(**sample_batch_device, target_class_idx=1)\n",
    "\n",
    "print(\"\\nVerifying that explainer(**data) and explainer.attribute(**data) produce\")\n",
    "print(\"identical results when random_seed is set...\")\n",
    "\n",
    "all_close = True\n",
    "for key in attr_from_attribute.keys():\n",
    "    if not torch.allclose(attr_from_attribute[key], attr_from_call[key], atol=1e-6):\n",
    "        all_close = False\n",
    "        print(f\"  ❌ {key}: Results differ!\")\n",
    "    else:\n",
    "        print(f\"  ✓ {key}: Results match\")\n",
    "\n",
    "if all_close:\n",
    "    print(\"\\n✓ All attributions match! Callable interface works correctly.\")\n",
    "else:\n",
    "    print(\"\\n❌ Some attributions differ. Check random seed configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d9e033",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **SHAP Initialization**: How to configure the `ShapExplainer` with custom parameters\n",
    "2. **Attribution Computation**: Computing SHAP values for mortality prediction\n",
    "3. **Feature Importance**: Identifying the most important features driving predictions\n",
    "4. **Baseline Strategies**: Comparing automatic vs. custom baseline generation\n",
    "5. **Reproducibility**: Using random seeds for deterministic results\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- **Positive SHAP values** indicate features that increase the mortality prediction\n",
    "- **Negative SHAP values** indicate features that decrease the mortality prediction\n",
    "- The sum of SHAP values approximates the difference between the model's prediction and the baseline\n",
    "- Setting a `random_seed` ensures reproducible results across multiple runs\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Analyze multiple patients to identify common patterns\n",
    "- Compare SHAP results with other interpretability methods (DeepLIFT, Integrated Gradients)\n",
    "- Visualize SHAP values using summary plots or waterfall charts\n",
    "- Use SHAP insights to improve model performance or identify data quality issues"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
