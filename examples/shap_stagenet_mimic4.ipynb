{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fe2649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"⚠️ GPU not available. Please enable GPU: Runtime > Change runtime type > GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0428f9a4",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "Install PyHealth and required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c349da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyHealth (adjust path/version as needed)\n",
    "!pip install pyhealth polars -q\n",
    "\n",
    "# If using development version from GitHub:\n",
    "# !pip install git+https://github.com/sunlabuiuc/PyHealth.git -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f4ba9",
   "metadata": {},
   "source": [
    "## 2. Download MIMIC-IV Demo Dataset\n",
    "\n",
    "Download the MIMIC-IV demo dataset. You'll need PhysioNet credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9b20b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create data directory\n",
    "data_dir = Path(\"/content/mimic-iv-demo/2.2\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download MIMIC-IV demo dataset\n",
    "# Note: Replace with actual download method or mount Google Drive with dataset\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(\"\\n⚠️ Please download MIMIC-IV demo dataset from:\")\n",
    "print(\"https://physionet.org/content/mimic-iv-demo/2.2/\")\n",
    "print(\"\\nOr mount Google Drive if you have the dataset stored there.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae78c2a5",
   "metadata": {},
   "source": [
    "## 3. Load Pre-trained Model Checkpoint\n",
    "\n",
    "Upload or download the pre-trained StageNet model checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5992a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create resources directory\n",
    "resources_dir = Path(\"/content/resources\")\n",
    "resources_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Upload model checkpoint\n",
    "# You can use Google Colab's file upload or download from URL\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "\n",
    "checkpoint_path = resources_dir / \"best.ckpt\"\n",
    "print(f\"Model checkpoint should be at: {checkpoint_path}\")\n",
    "print(f\"Checkpoint exists: {checkpoint_path.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6898e63",
   "metadata": {},
   "source": [
    "## 4. Load Dataset and Processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11338065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import torch\n",
    "\n",
    "from pyhealth.datasets import (\n",
    "    MIMIC4EHRDataset,\n",
    "    get_dataloader,\n",
    "    load_processors,\n",
    "    split_by_patient,\n",
    ")\n",
    "from pyhealth.interpret.methods import ShapExplainer\n",
    "from pyhealth.models import StageNet\n",
    "from pyhealth.tasks import MortalityPredictionStageNetMIMIC4\n",
    "\n",
    "# Configure dataset location\n",
    "dataset = MIMIC4EHRDataset(\n",
    "    root=\"/content/mimic-iv-demo/2.2/\",  # Adjust path as needed\n",
    "    tables=[\n",
    "        \"patients\",\n",
    "        \"admissions\",\n",
    "        \"diagnoses_icd\",\n",
    "        \"procedures_icd\",\n",
    "        \"labevents\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"Dataset loaded: {len(dataset.patients)} patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4d785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processors and set task\n",
    "input_processors, output_processors = load_processors(\"/content/resources/\")\n",
    "\n",
    "sample_dataset = dataset.set_task(\n",
    "    MortalityPredictionStageNetMIMIC4(),\n",
    "    cache_dir=\"/content/.cache/pyhealth/mimic4_stagenet_mortality\",\n",
    "    input_processors=input_processors,\n",
    "    output_processors=output_processors,\n",
    ")\n",
    "print(f\"Total samples: {len(sample_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c5f116",
   "metadata": {},
   "source": [
    "## 5. Load ICD Code Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4594eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_icd_description_map(dataset_root: str) -> dict:\n",
    "    \"\"\"Load ICD code → long title mappings from MIMIC-IV reference tables.\"\"\"\n",
    "    mapping = {}\n",
    "    root_path = Path(dataset_root).expanduser()\n",
    "    diag_path = root_path / \"hosp\" / \"d_icd_diagnoses.csv.gz\"\n",
    "    proc_path = root_path / \"hosp\" / \"d_icd_procedures.csv.gz\"\n",
    "\n",
    "    icd_dtype = {\"icd_code\": pl.Utf8, \"long_title\": pl.Utf8}\n",
    "\n",
    "    if diag_path.exists():\n",
    "        diag_df = pl.read_csv(\n",
    "            diag_path,\n",
    "            columns=[\"icd_code\", \"long_title\"],\n",
    "            dtypes=icd_dtype,\n",
    "        )\n",
    "        mapping.update(\n",
    "            zip(diag_df[\"icd_code\"].to_list(), diag_df[\"long_title\"].to_list())\n",
    "        )\n",
    "\n",
    "    if proc_path.exists():\n",
    "        proc_df = pl.read_csv(\n",
    "            proc_path,\n",
    "            columns=[\"icd_code\", \"long_title\"],\n",
    "            dtypes=icd_dtype,\n",
    "        )\n",
    "        mapping.update(\n",
    "            zip(proc_df[\"icd_code\"].to_list(), proc_df[\"long_title\"].to_list())\n",
    "        )\n",
    "\n",
    "    return mapping\n",
    "\n",
    "ICD_CODE_TO_DESC = load_icd_description_map(dataset.root)\n",
    "print(f\"Loaded {len(ICD_CODE_TO_DESC)} ICD code descriptions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4274bd9",
   "metadata": {},
   "source": [
    "## 6. Load Pre-trained StageNet Model on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f70a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "model = StageNet(\n",
    "    dataset=sample_dataset,\n",
    "    embedding_dim=128,\n",
    "    chunk_size=128,\n",
    "    levels=3,\n",
    "    dropout=0.3,\n",
    ")\n",
    "\n",
    "# Load checkpoint\n",
    "state_dict = torch.load(\"/content/resources/best.ckpt\", map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"\\nModel loaded successfully on {device}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5741ab",
   "metadata": {},
   "source": [
    "## 7. Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbda428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "_, _, test_data = split_by_patient(sample_dataset, [0.7, 0.1, 0.2], seed=42)\n",
    "test_loader = get_dataloader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "\n",
    "def move_batch_to_device(batch, target_device):\n",
    "    \"\"\"Move all tensors in batch to target device.\"\"\"\n",
    "    moved = {}\n",
    "    for key, value in batch.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            moved[key] = value.to(target_device)\n",
    "        elif isinstance(value, tuple):\n",
    "            moved[key] = tuple(v.to(target_device) for v in value)\n",
    "        else:\n",
    "            moved[key] = value\n",
    "    return moved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe56d5e",
   "metadata": {},
   "source": [
    "## 8. Define Helper Functions for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cce5100",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAB_CATEGORY_NAMES = MortalityPredictionStageNetMIMIC4.LAB_CATEGORY_NAMES\n",
    "\n",
    "def decode_token(idx: int, processor, feature_key: str):\n",
    "    \"\"\"Decode token index to human-readable string.\"\"\"\n",
    "    if processor is None or not hasattr(processor, \"code_vocab\"):\n",
    "        return str(idx)\n",
    "    reverse_vocab = {index: token for token, index in processor.code_vocab.items()}\n",
    "    token = reverse_vocab.get(idx, f\"<UNK:{idx}>\")\n",
    "\n",
    "    if feature_key == \"icd_codes\" and token not in {\"<unk>\", \"<pad>\"}:\n",
    "        desc = ICD_CODE_TO_DESC.get(token)\n",
    "        if desc:\n",
    "            return f\"{token}: {desc}\"\n",
    "\n",
    "    return token\n",
    "\n",
    "def unravel(flat_index: int, shape: torch.Size):\n",
    "    \"\"\"Convert flat index to multi-dimensional coordinates.\"\"\"\n",
    "    coords = []\n",
    "    remaining = flat_index\n",
    "    for dim in reversed(shape):\n",
    "        coords.append(remaining % dim)\n",
    "        remaining //= dim\n",
    "    return list(reversed(coords))\n",
    "\n",
    "def print_top_attributions(\n",
    "    attributions,\n",
    "    batch,\n",
    "    processors,\n",
    "    top_k: int = 10,\n",
    "):\n",
    "    \"\"\"Print top-k most important features from SHAP attributions.\"\"\"\n",
    "    for feature_key, attr in attributions.items():\n",
    "        attr_cpu = attr.detach().cpu()\n",
    "        if attr_cpu.dim() == 0 or attr_cpu.size(0) == 0:\n",
    "            continue\n",
    "\n",
    "        feature_input = batch[feature_key]\n",
    "        if isinstance(feature_input, tuple):\n",
    "            feature_input = feature_input[1]\n",
    "        feature_input = feature_input.detach().cpu()\n",
    "\n",
    "        flattened = attr_cpu[0].flatten()\n",
    "        if flattened.numel() == 0:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nFeature: {feature_key}\")\n",
    "        print(f\"  Shape: {attr_cpu[0].shape}\")\n",
    "        print(f\"  Total attribution sum: {flattened.sum().item():+.6f}\")\n",
    "        print(f\"  Mean attribution: {flattened.mean().item():+.6f}\")\n",
    "        \n",
    "        k = min(top_k, flattened.numel())\n",
    "        top_values, top_indices = torch.topk(flattened.abs(), k=k)\n",
    "        processor = processors.get(feature_key) if processors else None\n",
    "        is_continuous = torch.is_floating_point(feature_input)\n",
    "\n",
    "        print(f\"\\n  Top {k} most important features:\")\n",
    "        for rank, (_, flat_idx) in enumerate(zip(top_values, top_indices), 1):\n",
    "            attribution_value = flattened[flat_idx].item()\n",
    "            coords = unravel(flat_idx.item(), attr_cpu[0].shape)\n",
    "\n",
    "            if is_continuous:\n",
    "                actual_value = feature_input[0][tuple(coords)].item()\n",
    "                label = \"\"\n",
    "                if feature_key == \"labs\" and len(coords) >= 1:\n",
    "                    lab_idx = coords[-1]\n",
    "                    if lab_idx < len(LAB_CATEGORY_NAMES):\n",
    "                        label = f\"{LAB_CATEGORY_NAMES[lab_idx]} \"\n",
    "                print(\n",
    "                    f\"    {rank:2d}. idx={coords} {label}value={actual_value:.4f} \"\n",
    "                    f\"SHAP={attribution_value:+.6f}\"\n",
    "                )\n",
    "            else:\n",
    "                token_idx = int(feature_input[0][tuple(coords)].item())\n",
    "                token = decode_token(token_idx, processor, feature_key)\n",
    "                print(\n",
    "                    f\"    {rank:2d}. idx={coords} token='{token}' \"\n",
    "                    f\"SHAP={attribution_value:+.6f}\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ec480e",
   "metadata": {},
   "source": [
    "## 9. Initialize SHAP Explainer\n",
    "\n",
    "Initialize the SHAP explainer with Kernel SHAP configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae57044",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Initializing SHAP Explainer\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize SHAP explainer (Kernel SHAP)\n",
    "shap_explainer = ShapExplainer(model)\n",
    "\n",
    "print(\"\\nSHAP Configuration:\")\n",
    "print(f\"  Use embeddings: {shap_explainer.use_embeddings}\")\n",
    "print(f\"  Background samples: {shap_explainer.n_background_samples}\")\n",
    "print(f\"  Max coalitions: {shap_explainer.max_coalitions}\")\n",
    "print(f\"  Regularization: {shap_explainer.regularization}\")\n",
    "print(f\"  Device: {next(shap_explainer.model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95e8951",
   "metadata": {},
   "source": [
    "## 10. Get Model Prediction on Test Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb63b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample from test set\n",
    "sample_batch = next(iter(test_loader))\n",
    "sample_batch_device = move_batch_to_device(sample_batch, device)\n",
    "\n",
    "# Verify data is on GPU\n",
    "for key, val in sample_batch_device.items():\n",
    "    if isinstance(val, torch.Tensor):\n",
    "        print(f\"{key}: device={val.device}\")\n",
    "    elif isinstance(val, tuple) and len(val) > 0 and isinstance(val[0], torch.Tensor):\n",
    "        print(f\"{key}: device={val[0].device}\")\n",
    "\n",
    "# Get model prediction\n",
    "with torch.no_grad():\n",
    "    output = model(**sample_batch_device)\n",
    "    probs = output[\"y_prob\"]\n",
    "    label_key = model.label_key\n",
    "    true_label = sample_batch_device[label_key]\n",
    "    \n",
    "    # Handle binary classification (single probability output)\n",
    "    if probs.shape[-1] == 1:\n",
    "        prob_death = probs[0].item()\n",
    "        prob_survive = 1 - prob_death\n",
    "        preds = (probs > 0.5).long()\n",
    "    else:\n",
    "        # Multi-class classification\n",
    "        preds = torch.argmax(probs, dim=-1)\n",
    "        prob_survive = probs[0][0].item()\n",
    "        prob_death = probs[0][1].item()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Model Prediction for Sampled Patient\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"  True label: {int(true_label.item())} {'(Deceased)' if true_label.item() == 1 else '(Survived)'}\")\n",
    "    print(f\"  Predicted class: {int(preds.item())} {'(Deceased)' if preds.item() == 1 else '(Survived)'}\")\n",
    "    print(f\"  Probabilities: [Survive={prob_survive:.4f}, Death={prob_death:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2eb9c3",
   "metadata": {},
   "source": [
    "## 11. Compute SHAP Attributions (GPU-Accelerated)\n",
    "\n",
    "This step computes SHAP values using Kernel SHAP, running on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65de0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Computing SHAP Attributions on GPU\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Time the computation\n",
    "start_time = time.time()\n",
    "\n",
    "attributions = shap_explainer.attribute(**sample_batch_device, target_class_idx=1)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n✓ Computation completed in {elapsed:.2f} seconds\")\n",
    "\n",
    "# Verify attributions are on GPU\n",
    "print(\"\\nAttribution tensor devices:\")\n",
    "for key, val in attributions.items():\n",
    "    print(f\"  {key}: device={val.device}, shape={val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481c4c31",
   "metadata": {},
   "source": [
    "## 12. Analyze SHAP Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93490ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SHAP Attribution Results\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nSHAP values explain the contribution of each feature to the model's\")\n",
    "print(\"prediction of MORTALITY (class 1). Positive values increase the\")\n",
    "print(\"mortality prediction, negative values decrease it.\")\n",
    "\n",
    "print_top_attributions(attributions, sample_batch_device, input_processors, top_k=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5b8e9c",
   "metadata": {},
   "source": [
    "## 13. Test Different Target Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b02451",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Comparing SHAP Attributions for Different Target Classes\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compute for survival (class 0)\n",
    "print(\"\\nComputing attributions for SURVIVAL (class 0)...\")\n",
    "attr_survive = shap_explainer.attribute(**sample_batch_device, target_class_idx=0)\n",
    "\n",
    "# Compute for mortality (class 1)\n",
    "print(\"Computing attributions for MORTALITY (class 1)...\")\n",
    "attr_death = shap_explainer.attribute(**sample_batch_device, target_class_idx=1)\n",
    "\n",
    "print(\"\\n--- Features promoting SURVIVAL ---\")\n",
    "print_top_attributions(attr_survive, sample_batch_device, input_processors, top_k=5)\n",
    "\n",
    "print(\"\\n--- Features promoting MORTALITY ---\")\n",
    "print_top_attributions(attr_death, sample_batch_device, input_processors, top_k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cc5987",
   "metadata": {},
   "source": [
    "## 14. Verify GPU Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5c098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GPU Memory Usage\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    allocated = torch.cuda.memory_allocated(0) / 1e9\n",
    "    reserved = torch.cuda.memory_reserved(0) / 1e9\n",
    "    max_allocated = torch.cuda.max_memory_allocated(0) / 1e9\n",
    "    \n",
    "    print(f\"  Currently allocated: {allocated:.2f} GB\")\n",
    "    print(f\"  Reserved: {reserved:.2f} GB\")\n",
    "    print(f\"  Peak allocated: {max_allocated:.2f} GB\")\n",
    "    \n",
    "    # Reset peak stats\n",
    "    torch.cuda.reset_peak_memory_stats(0)\n",
    "else:\n",
    "    print(\"GPU not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483d95cd",
   "metadata": {},
   "source": [
    "## 15. Test Callable Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69867127",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Testing Callable Interface\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Both methods should produce identical results\n",
    "attr_from_attribute = shap_explainer.attribute(**sample_batch_device, target_class_idx=1)\n",
    "attr_from_call = shap_explainer(**sample_batch_device, target_class_idx=1)\n",
    "\n",
    "print(\"\\nVerifying that explainer(**data) and explainer.attribute(**data) produce\")\n",
    "print(\"identical results...\")\n",
    "\n",
    "all_close = True\n",
    "for key in attr_from_attribute.keys():\n",
    "    if not torch.allclose(attr_from_attribute[key], attr_from_call[key], atol=1e-6):\n",
    "        all_close = False\n",
    "        print(f\"  ❌ {key}: Results differ!\")\n",
    "    else:\n",
    "        print(f\"  ✓ {key}: Results match\")\n",
    "\n",
    "if all_close:\n",
    "    print(\"\\n✓ All attributions match! Callable interface works correctly.\")\n",
    "else:\n",
    "    print(\"\\n❌ Some attributions differ.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9d0d8e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. ✅ **GPU Setup**: Verified GPU availability and configured PyTorch to use CUDA\n",
    "2. ✅ **Model Loading**: Loaded pre-trained StageNet model on GPU\n",
    "3. ✅ **SHAP Computation**: Computed SHAP attributions on GPU for discrete features (ICD codes)\n",
    "4. ✅ **Feature Interpretation**: Identified which diagnosis/procedure codes and lab values most influenced mortality predictions\n",
    "5. ✅ **Multi-class Analysis**: Compared attributions for different target classes (survival vs. mortality)\n",
    "6. ✅ **GPU Optimization**: Verified all tensors and computations run on GPU\n",
    "\n",
    "**Key Takeaways:**\n",
    "- SHAP provides interpretable, theoretically-grounded feature attributions\n",
    "- GPU acceleration significantly speeds up coalition sampling and model evaluations\n",
    "- The method works seamlessly with discrete healthcare features like ICD codes\n",
    "- Positive SHAP values indicate features that increase the prediction, negative values decrease it"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
