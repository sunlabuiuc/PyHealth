{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHy2: Recreating SHy with PyHealth (Simplified, Stepwise)\n",
    "\n",
    "- Goal: Reproduce core ideas of SHy (patient hypergraphs, message passing, temporal phenotypes) using PyHealth for data handling and a minimal PyTorch model.\n",
    "- Rules for this notebook:\n",
    "  - Run step-by-step. After each checkpoint, share outputs before proceeding.\n",
    "  - CPU by default. If you switch to GPU, ensure tensors/devices are consistent.\n",
    "  - Keep seeds fixed for reproducibility.\n",
    "  - Weâ€™ll start with synthetic MIMIC-III from PyHealth for quick iteration, then document how to swap to real MIMIC.\n",
    "\n",
    "Checkpoints:\n",
    "1) Environment + imports (local PyHealth)\n",
    "2) Load synthetic MIMIC-III diagnoses and sanity checks\n",
    "3) Prepare patient sequences, vocabulary, and splits\n",
    "4) Implement simplified SHy modules (message passing + phenotypes)\n",
    "5) Training loop and metrics (Recall@k, nDCG@k)\n",
    "6) Explanations: show phenotypes per patient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background: What is SHy and why hypergraphs?\n",
    "- SHy (Self-Explaining Hypergraph Neural Networks) models each patient as a hypergraph: nodes are diagnosis codes; hyperedges are visits that connect the codes recorded together. This captures higher-order (non-pairwise) disease co-occurrences that sequence-only models may miss.\n",
    "- The model learns patient-specific code embeddings via message passing on the patientâ€™s hypergraph, then extracts K temporal phenotypes as concise, personalized explanations that drive the final prediction (a concept bottleneck).\n",
    "- Key advantages: (1) higher-order structure; (2) succinct, editable explanations; (3) robustness to missing codes by proposing plausible codeâ€“visit links before phenotype extraction.\n",
    "- Reference: Yu et al., â€œSelf-Explaining Hypergraph Neural Networks for Diagnosis Predictionâ€ (AAAI 2024). Code: https://github.com/ThunderbornSakana/SHy\n",
    "\n",
    "#### Overview of the pipeline in this notebook\n",
    "1) Build per-patient sequences of visits and a code vocabulary (ICD-9) using PyHealthâ€™s `MIMIC3Dataset`.\n",
    "2) For each patient, create an incidence matrix `P âˆˆ {0,1}^{|C|Ã—T}` (rows: codes; cols: visits): `P[i,j]=1` if code i appears in visit j.\n",
    "3) Learn code embeddings and apply UniGIN-like message passing: codes â†’ visits (aggregate codes per visit), then visits â†’ codes (aggregate visits per code) to get personalized code embeddings.\n",
    "4) Extract K temporal phenotypes via a differentiable binary mask over the (code, visit) grid using Gumbel-sigmoid; each phenotype selects a sub-hypergraph.\n",
    "5) For each phenotype, aggregate visit information with a GRU + location-based attention to obtain a phenotype embedding; combine K phenotype predictions via self-attention.\n",
    "6) Train with BCEWithLogits (multi-label next-visit codes); evaluate with Recall@k and nDCG@k; visualize explanations (Î± weights and top codes per phenotype).\n",
    "\n",
    "This notebook is CPU-friendly for development (synthetic MIMIC-III). It also documents how to switch to real MIMIC when credentialed. See the paper for full details; this notebook stands alone for key ideas and a working reproduction scaffold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data & preprocessing (PyHealth)\n",
    "- We use PyHealthâ€™s synthetic MIMIC-III endpoint for quick iteration. This avoids credentialing for real MIMIC and matches the `diagnoses_icd` schema used in the literature.\n",
    "- Patient API: `dataset.get_patient(pid)` â†’ `patient.get_events('diagnoses_icd')` yields time-ordered diagnosis events with attributes like `hadm_id` (visit ID) and `icd9_code`.\n",
    "- We group events by `hadm_id` to form a sequence of visits per patient, each visit being an unordered set of ICD-9 codes.\n",
    "- We build a code vocabulary (ICD-9) and split patients 80/10/10 into train/val/test at the patient level to avoid leakage.\n",
    "- Incidence matrix `P` (codes Ã— visits) is constructed from each patientâ€™s history; the prediction target is the final visitâ€™s multi-hot code vector.\n",
    "\n",
    "Caveats: On Windows, PyHealth path normalization for URLs may need a POSIX fix (we include a minimal patch). PyHealth requires `polars`; install it if missing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics used in this notebook\n",
    "- **Recall@k**: fraction of true codes for the next visit that appear in the top-k predicted codes.\n",
    "- **nDCG@k**: rank-sensitive metric; higher weight to true codes ranked near the top. We compute DCG using binary relevance and normalize by the ideal DCG.\n",
    "\n",
    "These match the ranking-oriented evaluation used in the paper for diagnosis prediction; we report k âˆˆ {10,20}.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'torch_version': '2.7.0+cu118', 'device': 'cpu'}\n",
      "PyHealth import: OK (local repo)\n"
     ]
    }
   ],
   "source": [
    "# Environment & imports\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Device (default CPU)\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "print({\n",
    "    \"torch_version\": torch.__version__,\n",
    "    \"device\": str(DEVICE),\n",
    "})\n",
    "\n",
    "# Use local PyHealth repo to avoid pip conflicts\n",
    "# Adjust path if needed based on your workspace\n",
    "LOCAL_PYHEALTH_PATH = os.path.join(os.getcwd(), \"PyHealth\")\n",
    "if os.path.isdir(LOCAL_PYHEALTH_PATH) and LOCAL_PYHEALTH_PATH not in sys.path:\n",
    "    sys.path.insert(0, LOCAL_PYHEALTH_PATH)\n",
    "\n",
    "try:\n",
    "    from pyhealth.datasets import MIMIC3Dataset, MIMIC4Dataset\n",
    "    print(\"PyHealth import: OK (local repo)\")\n",
    "except Exception as e:\n",
    "    print(\"PyHealth import failed. Please verify local repo path at ./PyHealth\")\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install missing dependency for local PyHealth: polars\n",
    "If the previous cell failed with `ModuleNotFoundError: No module named 'polars'`, run the next cell once, then re-run the import cell above.\n",
    "\n",
    "Note: On Windows, you may need to restart the kernel after installation if imports still fail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install polars version compatible with local PyHealth\n",
    "#%pip install \"polars~=1.31.0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load synthetic MIMIC-III (diagnoses only)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated pyhealth.datasets.base_dataset.clean_path for URL POSIX normalization.\n"
     ]
    }
   ],
   "source": [
    "# Fix URL path normalization in local PyHealth on Windows\n",
    "# PyHealth currently uses os.path.normpath on URL paths, which inserts backslashes.\n",
    "# Override clean_path to use POSIX normalization for URLs.\n",
    "import posixpath\n",
    "from urllib.parse import urlparse, urlunparse\n",
    "import pyhealth.datasets.base_dataset as _bd\n",
    "from pathlib import Path\n",
    "\n",
    "def _clean_path_patch(path: str) -> str:\n",
    "    if _bd.is_url(path):\n",
    "        parsed = urlparse(path)\n",
    "        cleaned_path = posixpath.normpath(parsed.path)\n",
    "        return urlunparse(parsed._replace(path=cleaned_path))\n",
    "    else:\n",
    "        return str(Path(path).expanduser().resolve())\n",
    "\n",
    "_bd.clean_path = _clean_path_patch\n",
    "print(\"Updated pyhealth.datasets.base_dataset.clean_path for URL POSIX normalization.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No sample patient available. Run the sequences/splits cell first.\n"
     ]
    }
   ],
   "source": [
    "# Safe shape check (fallback if sample_pid not set)\n",
    "if 'sample_pid' not in locals() or not sample_pid:\n",
    "    if 'patient_to_visits' in locals() and len(patient_to_visits) > 0:\n",
    "        sample_pid = next(iter(patient_to_visits.keys()))\n",
    "    else:\n",
    "        sample_pid = None\n",
    "\n",
    "if sample_pid:\n",
    "    seq = patient_to_visits[sample_pid]\n",
    "    P = build_incidence(seq[:-1], code_to_index, num_codes)  # history only\n",
    "    M = torch.randn(num_codes, CFG[\"d_c\"])                   # dummy embeddings for check\n",
    "    V = compute_visit_embeddings(M, P)\n",
    "    print({\n",
    "        \"P_shape\": tuple(P.shape),\n",
    "        \"M_shape\": tuple(M.shape),\n",
    "        \"V_shape\": tuple(V.shape),\n",
    "    })\n",
    "else:\n",
    "    print(\"No sample patient available. Run the sequences/splits cell first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No config path provided, using default config\n",
      "Initializing mimic3 dataset from https://storage.googleapis.com/pyhealth/Synthetic_MIMIC-III/ (dev mode: False)\n",
      "Scanning table: patients from https://storage.googleapis.com/pyhealth/Synthetic_MIMIC-III/PATIENTS.csv.gz\n",
      "Original path does not exist. Using alternative: https://storage.googleapis.com/pyhealth/Synthetic_MIMIC-III/PATIENTS.csv\n",
      "Scanning table: admissions from https://storage.googleapis.com/pyhealth/Synthetic_MIMIC-III/ADMISSIONS.csv.gz\n",
      "Original path does not exist. Using alternative: https://storage.googleapis.com/pyhealth/Synthetic_MIMIC-III/ADMISSIONS.csv\n",
      "Scanning table: icustays from https://storage.googleapis.com/pyhealth/Synthetic_MIMIC-III/ICUSTAYS.csv.gz\n",
      "Original path does not exist. Using alternative: https://storage.googleapis.com/pyhealth/Synthetic_MIMIC-III/ICUSTAYS.csv\n",
      "Scanning table: diagnoses_icd from https://storage.googleapis.com/pyhealth/Synthetic_MIMIC-III/DIAGNOSES_ICD.csv.gz\n",
      "Original path does not exist. Using alternative: https://storage.googleapis.com/pyhealth/Synthetic_MIMIC-III/DIAGNOSES_ICD.csv\n",
      "Joining with table: https://storage.googleapis.com/pyhealth/Synthetic_MIMIC-III/ADMISSIONS.csv.gz\n",
      "Original path does not exist. Using alternative: https://storage.googleapis.com/pyhealth/Synthetic_MIMIC-III/ADMISSIONS.csv\n",
      "Collecting global event dataframe...\n",
      "Renaming column SUBJECT_ID to lowercase subject_id\n",
      "Renaming column GENDER to lowercase gender\n",
      "Renaming column DOB to lowercase dob\n",
      "Renaming column DOD to lowercase dod\n",
      "Renaming column DOD_HOSP to lowercase dod_hosp\n",
      "Renaming column DOD_SSN to lowercase dod_ssn\n",
      "Renaming column EXPIRE_FLAG to lowercase expire_flag\n",
      "Renaming column SUBJECT_ID to lowercase subject_id\n",
      "Renaming column HADM_ID to lowercase hadm_id\n",
      "Renaming column ADMITTIME to lowercase admittime\n",
      "Renaming column DISCHTIME to lowercase dischtime\n",
      "Renaming column DEATHTIME to lowercase deathtime\n",
      "Renaming column ADMISSION_TYPE to lowercase admission_type\n",
      "Renaming column ADMISSION_LOCATION to lowercase admission_location\n",
      "Renaming column DISCHARGE_LOCATION to lowercase discharge_location\n",
      "Renaming column INSURANCE to lowercase insurance\n",
      "Renaming column LANGUAGE to lowercase language\n",
      "Renaming column RELIGION to lowercase religion\n",
      "Renaming column MARITAL_STATUS to lowercase marital_status\n",
      "Renaming column ETHNICITY to lowercase ethnicity\n",
      "Renaming column EDREGTIME to lowercase edregtime\n",
      "Renaming column EDOUTTIME to lowercase edouttime\n",
      "Renaming column DIAGNOSIS to lowercase diagnosis\n",
      "Renaming column HOSPITAL_EXPIRE_FLAG to lowercase hospital_expire_flag\n",
      "Renaming column HAS_CHARTEVENTS_DATA to lowercase has_chartevents_data\n",
      "Renaming column SUBJECT_ID to lowercase subject_id\n",
      "Renaming column HADM_ID to lowercase hadm_id\n",
      "Renaming column ICUSTAY_ID to lowercase icustay_id\n",
      "Renaming column DBSOURCE to lowercase dbsource\n",
      "Renaming column FIRST_CAREUNIT to lowercase first_careunit\n",
      "Renaming column LAST_CAREUNIT to lowercase last_careunit\n",
      "Renaming column FIRST_WARDID to lowercase first_wardid\n",
      "Renaming column LAST_WARDID to lowercase last_wardid\n",
      "Renaming column INTIME to lowercase intime\n",
      "Renaming column OUTTIME to lowercase outtime\n",
      "Renaming column LOS to lowercase los\n",
      "Renaming column SUBJECT_ID to lowercase subject_id\n",
      "Renaming column HADM_ID to lowercase hadm_id\n",
      "Renaming column SEQ_NUM to lowercase seq_num\n",
      "Renaming column ICD9_CODE to lowercase icd9_code\n",
      "Renaming column SUBJECT_ID to lowercase subject_id\n",
      "Renaming column HADM_ID to lowercase hadm_id\n",
      "Renaming column ADMITTIME to lowercase admittime\n",
      "Renaming column DISCHTIME to lowercase dischtime\n",
      "Renaming column DEATHTIME to lowercase deathtime\n",
      "Renaming column ADMISSION_TYPE to lowercase admission_type\n",
      "Renaming column ADMISSION_LOCATION to lowercase admission_location\n",
      "Renaming column DISCHARGE_LOCATION to lowercase discharge_location\n",
      "Renaming column INSURANCE to lowercase insurance\n",
      "Renaming column LANGUAGE to lowercase language\n",
      "Renaming column RELIGION to lowercase religion\n",
      "Renaming column MARITAL_STATUS to lowercase marital_status\n",
      "Renaming column ETHNICITY to lowercase ethnicity\n",
      "Renaming column EDREGTIME to lowercase edregtime\n",
      "Renaming column EDOUTTIME to lowercase edouttime\n",
      "Renaming column DIAGNOSIS to lowercase diagnosis\n",
      "Renaming column HOSPITAL_EXPIRE_FLAG to lowercase hospital_expire_flag\n",
      "Renaming column HAS_CHARTEVENTS_DATA to lowercase has_chartevents_data\n",
      "Collected dataframe with shape: (635929, 31)\n",
      "Dataset: mimic3\n",
      "Dev mode: False\n",
      "Number of patients: 49993\n",
      "Number of events: 635929\n",
      "PEEK\n",
      "\n",
      "Patient: 28890\n",
      "diagnoses_icd events: 12\n",
      "\n",
      "Patient: 36391\n",
      "diagnoses_icd events: 5\n"
     ]
    }
   ],
   "source": [
    "# Synthetic MIMIC-III via PyHealth (new API)\n",
    "\n",
    "m3 = MIMIC3Dataset(\n",
    "    root=\"https://storage.googleapis.com/pyhealth/Synthetic_MIMIC-III/\",\n",
    "    tables=[\"diagnoses_icd\"],\n",
    ")\n",
    "\n",
    "# Print basic stats\n",
    "m3.stats()\n",
    "print(\"PEEK\")\n",
    "from itertools import islice\n",
    "for p in islice(m3.iter_patients(), 2):\n",
    "    print(\"\\nPatient:\", p.patient_id)\n",
    "    diag_events = p.get_events(event_type=\"diagnoses_icd\")\n",
    "    print(\"diagnoses_icd events:\", len(diag_events))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare patient sequences, code vocabulary, and splits\n",
    "We convert each patient into a sequence of visits where each visit is a set of CCSCM codes. We then build a code vocabulary and split patients into train/val/test (80/10/10).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d_c': 64, 'Z': 2, 'K': 3, 'd_hid': 128, 'd_Q': 64, 'd_V': 64, 'tau': 1.0, 'lr': 0.001, 'epochs': 3, 'topk_eval': [10, 20], 'lambda_eps': 0.0, 'lambda_eta': 0.0, 'lambda_omega': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Model/training config\n",
    "CFG = {\n",
    "    \"d_c\": 64,            # code embedding dim\n",
    "    \"Z\": 2,               # message passing layers\n",
    "    \"K\": 3,               # number of phenotypes (keep small for CPU)\n",
    "    \"d_hid\": 128,         # GRU hidden dim\n",
    "    \"d_Q\": 64,            # self-attn dims\n",
    "    \"d_V\": 64,\n",
    "    \"tau\": 1.0,           # Gumbel temperature\n",
    "    \"lr\": 1e-3,\n",
    "    \"epochs\": 3,          # small dev pass; raise later\n",
    "    \"topk_eval\": [10, 20],\n",
    "    \"lambda_eps\": 0.0,    # Îµ for fidelity loss (placeholder)\n",
    "    \"lambda_eta\": 0.0,    # Î· for distinctness loss (placeholder)\n",
    "    \"lambda_omega\": 0.0,  # Ï‰ for alpha loss (placeholder)\n",
    "}\n",
    "print(CFG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers: multi-hot encodings, incidence matrix, visit embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def codes_to_multihot(codes: List[str], code_to_index: Dict[str, int], num_codes: int) -> torch.Tensor:\n",
    "    v = torch.zeros(num_codes, dtype=torch.float32)\n",
    "    for c in codes:\n",
    "        idx = code_to_index.get(c, None)\n",
    "        if idx is not None:\n",
    "            v[idx] = 1.0\n",
    "    return v\n",
    "\n",
    "\n",
    "def build_incidence(visits_codes: List[List[str]], code_to_index: Dict[str, int], num_codes: int) -> torch.Tensor:\n",
    "    T = len(visits_codes)\n",
    "    P = torch.zeros((num_codes, T), dtype=torch.float32)\n",
    "    for j, codes in enumerate(visits_codes):\n",
    "        for c in codes:\n",
    "            idx = code_to_index.get(c, None)\n",
    "            if idx is not None:\n",
    "                P[idx, j] = 1.0\n",
    "    return P\n",
    "\n",
    "\n",
    "def compute_visit_embeddings(M: torch.Tensor, P: torch.Tensor) -> torch.Tensor:\n",
    "    # M: [|C|, d_c], P: [|C|, T] -> V: [T, d_c]\n",
    "    # mean over codes per visit (avoid div by zero)\n",
    "    codes_per_visit = P.sum(dim=0).clamp(min=1.0)  # [T]\n",
    "    V = (P.t() @ M) / codes_per_visit.unsqueeze(-1)\n",
    "    return V\n",
    "\n",
    "# Quick shape check on a sample patient\n",
    "if sample_pid:\n",
    "    seq = patient_to_visits[sample_pid]\n",
    "    P = build_incidence(seq[:-1], code_to_index, num_codes)  # history only\n",
    "    M = torch.randn(num_codes, CFG[\"d_c\"])  # dummy embeddings for check\n",
    "    V = compute_visit_embeddings(M, P)\n",
    "    print({\n",
    "        \"P_shape\": tuple(P.shape),\n",
    "        \"M_shape\": tuple(M.shape),\n",
    "        \"V_shape\": tuple(V.shape),\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics: Recall@k, nDCG@k\n",
    "Weâ€™ll compute these on sigmoid probabilities against multi-hot labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(probs: torch.Tensor, labels: torch.Tensor, k: int) -> float:\n",
    "    # probs, labels: [|C|]\n",
    "    topk = torch.topk(probs, k=k).indices\n",
    "    hits = labels[topk].sum().item()\n",
    "    denom = labels.sum().item()\n",
    "    if denom == 0:\n",
    "        return 1.0  # if no positives, treat as perfect (or skip)\n",
    "    return hits / denom\n",
    "\n",
    "\n",
    "def ndcg_at_k(probs: torch.Tensor, labels: torch.Tensor, k: int) -> float:\n",
    "    # Compute DCG with binary relevance\n",
    "    topk = torch.topk(probs, k=k).indices\n",
    "    gains = labels[topk]\n",
    "    discounts = 1.0 / torch.log2(torch.arange(2, k + 2, dtype=torch.float32))\n",
    "    dcg = (gains * discounts).sum().item()\n",
    "    # Ideal DCG\n",
    "    ideal_k = min(int(labels.sum().item()), k)\n",
    "    if ideal_k == 0:\n",
    "        return 1.0\n",
    "    idcg = discounts[:ideal_k].sum().item()\n",
    "    return dcg / idcg\n",
    "\n",
    "# Quick check\n",
    "if sample_pid:\n",
    "    test_probs = torch.rand(num_codes)\n",
    "    test_labels = codes_to_multihot(patient_to_visits[sample_pid][-1], code_to_index, num_codes)\n",
    "    for k in CFG[\"topk_eval\"]:\n",
    "        print(f\"recall@{k}\", recall_at_k(test_probs, test_labels, k))\n",
    "        print(f\"ndcg@{k}\", ndcg_at_k(test_probs, test_labels, k))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Embeddings, UniGIN-like layer, Phenotype extractor, SHy model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49993 unique patient IDs\n",
      "{'num_patients_all': 49993, 'num_patients_seq>=2': 2085, 'num_codes': 5691}\n",
      "{'train': 1668, 'val': 208, 'test': 209}\n",
      "Sample patient: 45482\n",
      "Sequence lengths (visits): [7, 37]\n",
      "First visit codes: ['2449', '2724', '2768', '4019', '5789', '85221', '9120']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Build sequences: patient -> list[visit_codes] using new Patient API\n",
    "patient_to_visits: Dict[str, List[List[str]]] = {}\n",
    "code_counter = defaultdict(int)\n",
    "\n",
    "for pid in m3.unique_patient_ids:\n",
    "    patient = m3.get_patient(pid)\n",
    "    events = patient.get_events(event_type=\"diagnoses_icd\")  # sorted by timestamp\n",
    "    if not events:\n",
    "        continue\n",
    "\n",
    "    visits_codes_map: Dict[str, set] = {}\n",
    "    visit_earliest_ts: Dict[str, any] = {}\n",
    "\n",
    "    for ev in events:\n",
    "        hadm = ev.attr_dict.get(\"hadm_id\")\n",
    "        code = ev.attr_dict.get(\"icd9_code\")\n",
    "        if hadm is None or code is None:\n",
    "            continue\n",
    "        visits_codes_map.setdefault(hadm, set()).add(str(code))\n",
    "        code_counter[str(code)] += 1\n",
    "        if hadm not in visit_earliest_ts:\n",
    "            visit_earliest_ts[hadm] = ev.timestamp\n",
    "\n",
    "    if not visits_codes_map:\n",
    "        continue\n",
    "\n",
    "    ordered_hadm = sorted(visits_codes_map.keys(), key=lambda h: visit_earliest_ts.get(h))\n",
    "    visits_codes = [sorted(list(visits_codes_map[h])) for h in ordered_hadm]\n",
    "    if visits_codes:\n",
    "        patient_to_visits[pid] = visits_codes\n",
    "\n",
    "# Filter patients with at least 2 historical visits (to predict next visit)\n",
    "patient_ids = [pid for pid, seq in patient_to_visits.items() if len(seq) >= 2]\n",
    "\n",
    "# Code vocabulary (ICD-9 codes)\n",
    "codes_sorted = sorted(code_counter.keys())\n",
    "code_to_index = {c: i for i, c in enumerate(codes_sorted)}\n",
    "index_to_code = {i: c for c, i in code_to_index.items()}\n",
    "num_codes = len(code_to_index)\n",
    "\n",
    "print({\n",
    "    \"num_patients_all\": len(m3.unique_patient_ids),\n",
    "    \"num_patients_seq>=2\": len(patient_ids),\n",
    "    \"num_codes\": num_codes,\n",
    "})\n",
    "\n",
    "# Train/val/test split (patient-level)\n",
    "train_ids, temp_ids = train_test_split(patient_ids, test_size=0.2, random_state=SEED)\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=SEED)\n",
    "\n",
    "print({\n",
    "    \"train\": len(train_ids),\n",
    "    \"val\": len(val_ids),\n",
    "    \"test\": len(test_ids),\n",
    "})\n",
    "\n",
    "# Show a tiny sample\n",
    "sample_pid = train_ids[0] if len(train_ids) > 0 else None\n",
    "if sample_pid:\n",
    "    print(\"Sample patient:\", sample_pid)\n",
    "    print(\"Sequence lengths (visits):\", [len(v) for v in patient_to_visits[sample_pid]])\n",
    "    print(\"First visit codes:\", patient_to_visits[sample_pid][0][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model OK: 1.230976 M params\n"
     ]
    }
   ],
   "source": [
    "class CodeEmbedding(nn.Module):\n",
    "    def __init__(self, num_codes: int, d_c: int):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_codes, d_c)\n",
    "    def forward(self) -> torch.Tensor:\n",
    "        # return full table [|C|, d_c]\n",
    "        idx = torch.arange(self.emb.num_embeddings, device=self.emb.weight.device)\n",
    "        return self.emb(idx)\n",
    "\n",
    "\n",
    "class UniGINLayer(nn.Module):\n",
    "    def __init__(self, d_c: int):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(d_c, d_c)\n",
    "        self.eps = nn.Parameter(torch.tensor(0.0))\n",
    "        self.act = nn.LeakyReLU()\n",
    "    def forward(self, M: torch.Tensor, P: torch.Tensor) -> torch.Tensor:\n",
    "        # M: [|C|, d_c], P: [|C|, T]\n",
    "        V = compute_visit_embeddings(M, P)  # [T, d_c]\n",
    "        # sum over visits containing code i: (P[i, :] @ V)\n",
    "        code_to_visit_agg = P @ V  # [|C|, d_c]\n",
    "        updated = (1.0 + self.eps) * M + code_to_visit_agg\n",
    "        return self.act(self.lin(updated))\n",
    "\n",
    "\n",
    "class PhenotypeExtractor(nn.Module):\n",
    "    def __init__(self, d_c: int, K: int):\n",
    "        super().__init__()\n",
    "        self.K = K\n",
    "        # MLP on concat [Mi || Vj] => scalar prob\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2 * d_c, d_c), nn.ReLU(), nn.Linear(d_c, 1)\n",
    "        )\n",
    "    def forward(self, M: torch.Tensor, P: torch.Tensor, tau: float) -> torch.Tensor:\n",
    "        # M: [|C|, d_c], P: [|C|, T]\n",
    "        V = compute_visit_embeddings(M, P)  # [T, d_c]\n",
    "        C, T = P.shape\n",
    "        # Build pairwise inputs [C*T, 2*d_c]\n",
    "        Mi = M.unsqueeze(1).expand(C, T, M.size(1))\n",
    "        Vj = V.unsqueeze(0).expand(C, T, V.size(1))\n",
    "        pair = torch.cat([Mi, Vj], dim=-1)  # [C, T, 2*d_c]\n",
    "        logits = self.fc(pair).squeeze(-1)  # [C, T]\n",
    "        masks = []\n",
    "        for _ in range(self.K):\n",
    "            # Gumbel-sigmoid\n",
    "            u = torch.rand_like(logits)\n",
    "            g0 = -torch.log(-torch.log(u + 1e-9) + 1e-9)\n",
    "            g1 = -torch.log(-torch.log(1 - u + 1e-9) + 1e-9)\n",
    "            z = torch.sigmoid((logits + g0 - g1) / max(tau, 1e-6))\n",
    "            # Hard binary in forward, soft in backward (straight-through)\n",
    "            hard = (z > 0.5).float()\n",
    "            z = z + (hard - z).detach()\n",
    "            # Ensure we do not exceed original edges too early: we allow both 0/1; keep simple\n",
    "            masks.append(z)\n",
    "        # stack -> [K, C, T]\n",
    "        return torch.stack(masks, dim=0)\n",
    "\n",
    "\n",
    "class SelfAttentionK(nn.Module):\n",
    "    def __init__(self, d_hid: int, d_q: int, d_v: int, K: int):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(d_hid, d_q)\n",
    "        self.k = nn.Linear(d_hid, d_q)\n",
    "        self.v = nn.Linear(d_hid, d_v)\n",
    "        self.out = nn.Linear(d_v, 1)  # scalar weight per phenotype\n",
    "        self.K = K\n",
    "    def forward(self, U: torch.Tensor) -> torch.Tensor:\n",
    "        # U: [K, d_hid]\n",
    "        Q = self.q(U)\n",
    "        Kk = self.k(U)\n",
    "        Vv = self.v(U)\n",
    "        attn = torch.softmax((Q @ Kk.t()) / math.sqrt(Kk.size(-1)), dim=-1)  # [K, K]\n",
    "        heads = attn @ Vv  # [K, d_v]\n",
    "        alpha_logits = self.out(heads).squeeze(-1)  # [K]\n",
    "        alpha = torch.softmax(alpha_logits, dim=-1)\n",
    "        return alpha\n",
    "\n",
    "\n",
    "class SHyModel(nn.Module):\n",
    "    def __init__(self, num_codes: int, cfg: Dict):\n",
    "        super().__init__()\n",
    "        self.num_codes = num_codes\n",
    "        self.d_c = cfg[\"d_c\"]\n",
    "        self.Z = cfg[\"Z\"]\n",
    "        self.K = cfg[\"K\"]\n",
    "        self.tau = cfg[\"tau\"]\n",
    "        self.emb = CodeEmbedding(num_codes, self.d_c)\n",
    "        self.mp_layers = nn.ModuleList([UniGINLayer(self.d_c) for _ in range(self.Z)])\n",
    "        self.phenos = PhenotypeExtractor(self.d_c, self.K)\n",
    "        self.gru = nn.GRU(self.d_c, cfg[\"d_hid\"], batch_first=True)\n",
    "        self.visit_attn = nn.Sequential(\n",
    "            nn.Linear(cfg[\"d_hid\"], cfg[\"d_hid\"]), nn.Tanh(), nn.Linear(cfg[\"d_hid\"], 1)\n",
    "        )\n",
    "        self.self_attn_k = SelfAttentionK(cfg[\"d_hid\"], cfg[\"d_Q\"], cfg[\"d_V\"], self.K)\n",
    "        self.cls = nn.Linear(cfg[\"d_hid\"], num_codes)\n",
    "    def forward(self, P: torch.Tensor) -> Tuple[torch.Tensor, Dict]:\n",
    "        # P: [|C|, T]\n",
    "        M = self.emb().to(P.device)  # [|C|, d_c]\n",
    "        for layer in self.mp_layers:\n",
    "            M = layer(M, P)\n",
    "        masks = self.phenos(M, P, self.tau)  # [K, |C|, T]\n",
    "        V = compute_visit_embeddings(M, P)  # [T, d_c]\n",
    "        U_list = []\n",
    "        logits_k = []\n",
    "        for k in range(self.K):\n",
    "            Psi_k = masks[k]  # [|C|, T]\n",
    "            Vk = (Psi_k.t() @ M)  # [T, d_c]\n",
    "            # GRU over visits\n",
    "            H, _ = self.gru(Vk.unsqueeze(0))  # [1, T, d_hid]\n",
    "            H = H.squeeze(0)  # [T, d_hid]\n",
    "            # location-based attention\n",
    "            w = self.visit_attn(H).squeeze(-1)  # [T]\n",
    "            alpha_t = torch.softmax(w, dim=-1)\n",
    "            Uk = (alpha_t.unsqueeze(-1) * H).sum(dim=0)  # [d_hid]\n",
    "            U_list.append(Uk)\n",
    "            logits_k.append(self.cls(Uk))  # [|C|]\n",
    "        U = torch.stack(U_list, dim=0)  # [K, d_hid]\n",
    "        alpha = self.self_attn_k(U)      # [K]\n",
    "        logits_k = torch.stack(logits_k, dim=0)  # [K, |C|]\n",
    "        logits = (alpha.unsqueeze(-1) * logits_k).sum(dim=0)  # [|C|]\n",
    "        aux = {\"masks\": masks, \"alpha\": alpha}\n",
    "        return logits, aux\n",
    "\n",
    "\n",
    "# Instantiate\n",
    "model = SHyModel(num_codes=num_codes, cfg=CFG).to(DEVICE)\n",
    "print(\"Model OK:\", sum(p.numel() for p in model.parameters())/1e6, \"M params\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data builder (one-step prediction)\n",
    "We predict the last visit from all previous visits for each patient. Run to build simple lists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_examples': 1668, 'val_examples': 208, 'test_examples': 209}\n"
     ]
    }
   ],
   "source": [
    "def build_examples(patient_ids: List[str]) -> List[Tuple[torch.Tensor, torch.Tensor]]:\n",
    "    ex = []\n",
    "    for pid in patient_ids:\n",
    "        seq = patient_to_visits[pid]\n",
    "        if len(seq) < 2:\n",
    "            continue\n",
    "        P = build_incidence(seq[:-1], code_to_index, num_codes)\n",
    "        y = codes_to_multihot(seq[-1], code_to_index, num_codes)\n",
    "        ex.append((P, y))\n",
    "    return ex\n",
    "\n",
    "train_ex = build_examples(train_ids)\n",
    "val_ex = build_examples(val_ids)\n",
    "test_ex = build_examples(test_ids)\n",
    "\n",
    "print({\n",
    "    \"train_examples\": len(train_ex),\n",
    "    \"val_examples\": len(val_ex),\n",
    "    \"test_examples\": len(test_ex),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop (L_pred only for now)\n",
    "- BCEWithLogitsLoss for multi-label next-visit codes.\n",
    "- CPU-safe one-example-at-a-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1, 'train_loss': 40.7386, 'val_loss': 0.0315}\n",
      "{'epoch': 2, 'train_loss': 0.0254, 'val_loss': 0.0312}\n",
      "{'epoch': 3, 'train_loss': 0.0132, 'val_loss': 0.0154}\n",
      "Test metrics: {'recall@10': 0.1697, 'recall@20': 0.2426, 'ndcg@10': 0.1792, 'ndcg@20': 0.1959}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recall@10': 0.1697437652624832,\n",
       " 'recall@20': 0.24264285865461746,\n",
       " 'ndcg@10': 0.17924969333149443,\n",
       " 'ndcg@20': 0.19592737824086373}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Loss / regularization helpers (same as before) ---\n",
    "crit = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def compute_distinctness_loss(masks: torch.Tensor) -> torch.Tensor:\n",
    "    # masks: [K, C, T]\n",
    "    K, C, T = masks.shape\n",
    "    loss = 0.0\n",
    "    I = torch.eye(K, device=masks.device)\n",
    "    for t in range(T):\n",
    "        B_t = masks[:, :, t].transpose(0, 1)  # [C, K]\n",
    "        G = B_t.transpose(0, 1) @ B_t        # [K, K]\n",
    "        loss = loss + torch.norm(I - G, p=\"fro\") ** 2\n",
    "    return loss / max(1, T)\n",
    "\n",
    "\n",
    "def compute_alpha_loss(alpha: torch.Tensor) -> torch.Tensor:\n",
    "    # Encourage non-uniform yet bounded alpha\n",
    "    var_term = torch.var(alpha, unbiased=False)\n",
    "    l2_term = (alpha ** 2).mean()\n",
    "    return -var_term + l2_term\n",
    "\n",
    "\n",
    "# --- NEW: full train+eval function that still runs the familiar loop ---\n",
    "def train_and_eval(\n",
    "    model: nn.Module,\n",
    "    train_examples: List[Tuple[torch.Tensor, torch.Tensor]],\n",
    "    val_examples: List[Tuple[torch.Tensor, torch.Tensor]],\n",
    "    test_examples: List[Tuple[torch.Tensor, torch.Tensor]],\n",
    "    epochs: int = 3,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the given model using the original epoch loop\n",
    "    and return test metrics.\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG[\"lr\"])\n",
    "    crit = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def run_epoch(examples: List[Tuple[torch.Tensor, torch.Tensor]], train: bool) -> float:\n",
    "        model.train() if train else model.eval()\n",
    "        total_loss = 0.0\n",
    "        with torch.set_grad_enabled(train):\n",
    "            for P, y in examples:\n",
    "                P = P.to(DEVICE)\n",
    "                y = y.to(DEVICE)\n",
    "\n",
    "                logits, aux = model(P)\n",
    "                base_loss = crit(logits, y)\n",
    "                loss = base_loss\n",
    "\n",
    "                # optional SHy regularizers\n",
    "                if CFG.get(\"lambda_eta\", 0.0) > 0.0:\n",
    "                    loss = loss + CFG[\"lambda_eta\"] * compute_distinctness_loss(aux[\"masks\"])\n",
    "                if CFG.get(\"lambda_omega\", 0.0) > 0.0:\n",
    "                    loss = loss + CFG[\"lambda_omega\"] * compute_alpha_loss(aux[\"alpha\"])\n",
    "\n",
    "                if train:\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        return total_loss / max(1, len(examples))\n",
    "\n",
    "    # ---- This is your old loop, unchanged in spirit ----\n",
    "    best_val = float(\"inf\")\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        tr = run_epoch(train_examples, train=True)\n",
    "        va = run_epoch(val_examples, train=False)\n",
    "        print({\"epoch\": epoch, \"train_loss\": round(tr, 4), \"val_loss\": round(va, 4)})\n",
    "\n",
    "        if va < best_val:\n",
    "            best_val = va\n",
    "            best_state = {k: v.cpu().detach().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    # Load best\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # Use your existing evaluate(examples) function here\n",
    "    test_metrics = evaluate(test_examples)\n",
    "    print(\"Test metrics:\", {k: round(v, 4) for k, v in test_metrics.items()})\n",
    "    return test_metrics\n",
    "\n",
    "\n",
    "baseline_results = train_and_eval(\n",
    "    model,\n",
    "    train_examples=train_ex,\n",
    "    val_examples=val_ex,\n",
    "    test_examples=test_ex,\n",
    "    epochs=CFG[\"epochs\"],\n",
    ")\n",
    "\n",
    "baseline_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanations: visualize phenotypes and weights for one test patient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha weights: [0.3333333432674408, 0.3333333432674408, 0.3333333432674408]\n",
      "phenotype 0: top codes -> ['4280', '41401', '51881', '5849', '496']\n",
      "phenotype 1: top codes -> ['4019', '42731', '41401', '5849', '496']\n",
      "phenotype 2: top codes -> ['4019', '42731', '5990', '51881', '5849']\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def show_explanations(example: Tuple[torch.Tensor, torch.Tensor], topn: int = 5):\n",
    "    P, y = example\n",
    "    logits, aux = model(P.to(DEVICE))\n",
    "    alpha = aux[\"alpha\"].cpu()\n",
    "    masks = aux[\"masks\"].cpu()  # [K, C, T]\n",
    "    probs = torch.sigmoid(logits.cpu())\n",
    "    print(\"alpha weights:\", alpha.tolist())\n",
    "    # For each phenotype, gather codes included at any visit and show top probs among those\n",
    "    for k in range(CFG[\"K\"]):\n",
    "        M_k = (masks[k].sum(dim=1) > 0).float()  # [C]\n",
    "        idx = torch.where(M_k > 0)[0]\n",
    "        if idx.numel() == 0:\n",
    "            print(f\"phenotype {k}: (empty)\")\n",
    "            continue\n",
    "        sel_probs = probs[idx]\n",
    "        top = torch.topk(sel_probs, k=min(topn, sel_probs.numel()))\n",
    "        top_code_indices = idx[top.indices].tolist()\n",
    "        top_codes = [index_to_code[int(j)] for j in top_code_indices]\n",
    "        print(f\"phenotype {k}: top codes ->\", top_codes)\n",
    "\n",
    "# Show explanations on first test example if available\n",
    "if len(test_ex) > 0:\n",
    "    show_explanations(test_ex[0], topn=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_patients_all': 49993, 'num_patients_seq>=2': 2085, 'num_codes': 5691}\n",
      "{'train': 1668, 'val': 208, 'test': 209}\n",
      "Sample patient: 45482\n",
      "Sequence lengths (visits): [7, 37]\n",
      "First visit codes: ['2449', '2724', '2768', '4019', '5789', '85221', '9120']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Build sequences: patient -> list[visit_codes] using new Patient API\n",
    "patient_to_visits: Dict[str, List[List[str]]] = {}\n",
    "code_counter = defaultdict(int)\n",
    "\n",
    "for pid in m3.unique_patient_ids:\n",
    "    patient = m3.get_patient(pid)\n",
    "    events = patient.get_events(event_type=\"diagnoses_icd\")  # sorted by timestamp\n",
    "    if not events:\n",
    "        continue\n",
    "\n",
    "    visits_codes_map: Dict[str, set] = {}\n",
    "    visit_earliest_ts: Dict[str, any] = {}\n",
    "\n",
    "    for ev in events:\n",
    "        hadm = ev.attr_dict.get(\"hadm_id\")\n",
    "        code = ev.attr_dict.get(\"icd9_code\")\n",
    "        if hadm is None or code is None:\n",
    "            continue\n",
    "        visits_codes_map.setdefault(hadm, set()).add(str(code))\n",
    "        code_counter[str(code)] += 1\n",
    "        if hadm not in visit_earliest_ts:\n",
    "            visit_earliest_ts[hadm] = ev.timestamp\n",
    "\n",
    "    if not visits_codes_map:\n",
    "        continue\n",
    "\n",
    "    ordered_hadm = sorted(visits_codes_map.keys(), key=lambda h: visit_earliest_ts.get(h))\n",
    "    visits_codes = [sorted(list(visits_codes_map[h])) for h in ordered_hadm]\n",
    "    if visits_codes:\n",
    "        patient_to_visits[pid] = visits_codes\n",
    "\n",
    "# Filter patients with at least 2 historical visits (to predict next visit)\n",
    "patient_ids = [pid for pid, seq in patient_to_visits.items() if len(seq) >= 2]\n",
    "\n",
    "# Code vocabulary (ICD-9 codes)\n",
    "codes_sorted = sorted(code_counter.keys())\n",
    "code_to_index = {c: i for i, c in enumerate(codes_sorted)}\n",
    "index_to_code = {i: c for c, i in code_to_index.items()}\n",
    "num_codes = len(code_to_index)\n",
    "\n",
    "print({\n",
    "    \"num_patients_all\": len(m3.unique_patient_ids),\n",
    "    \"num_patients_seq>=2\": len(patient_ids),\n",
    "    \"num_codes\": num_codes,\n",
    "})\n",
    "\n",
    "# Train/val/test split (patient-level)\n",
    "train_ids, temp_ids = train_test_split(patient_ids, test_size=0.2, random_state=SEED)\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=SEED)\n",
    "\n",
    "print({\n",
    "    \"train\": len(train_ids),\n",
    "    \"val\": len(val_ids),\n",
    "    \"test\": len(test_ids),\n",
    "})\n",
    "\n",
    "# Show a tiny sample\n",
    "sample_pid = train_ids[0] if len(train_ids) > 0 else None\n",
    "if sample_pid:\n",
    "    print(\"Sample patient:\", sample_pid)\n",
    "    print(\"Sequence lengths (visits):\", [len(v) for v in patient_to_visits[sample_pid]])\n",
    "    print(\"First visit codes:\", patient_to_visits[sample_pid][0][:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline: Simplified SHy components to implement next\n",
    "We will implement the following (scaffolded in the next steps):\n",
    "\n",
    "- CodeEmbedding: learnable embeddings for CCSCM codes (dimension d_c)\n",
    "- Simple patient hypergraph builder per batch (incidence P: |C| x T)\n",
    "- One or more UniGIN-like message passing layers (codesâ†’visitsâ†’codes)\n",
    "- PhenotypeExtractor: K binary masks via Gumbel-Softmax over (code, visit) pairs\n",
    "- GRU+attention over visits per phenotype; self-attention over K phenotypes\n",
    "- Final prediction layer with sigmoid; ranking metrics for evaluation\n",
    "- Loss: L = L_pred + ÎµÂ·L_fidelity + Î·Â·L_distinct + Ï‰Â·L_alpha (start with L_pred, add others iteratively)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prepared': True, 'num_patients_seq>=2': 2085, 'num_codes': 5691, 'train_examples': 1668, 'val_examples': 208, 'test_examples': 209}\n"
     ]
    }
   ],
   "source": [
    "# Order-independent setup: build sequences, vocab, splits, and examples (run once)\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Build patient sequences from diagnoses_icd (icd9_code grouped by hadm_id)\n",
    "patient_to_visits = {}\n",
    "code_counter = defaultdict(int)\n",
    "for pid in m3.unique_patient_ids:\n",
    "    patient = m3.get_patient(pid)\n",
    "    events = patient.get_events(event_type=\"diagnoses_icd\")\n",
    "    if not events:\n",
    "        continue\n",
    "    visits_codes_map = {}\n",
    "    visit_earliest_ts = {}\n",
    "    for ev in events:\n",
    "        hadm = ev.attr_dict.get(\"hadm_id\")\n",
    "        code = ev.attr_dict.get(\"icd9_code\")\n",
    "        if hadm is None or code is None:\n",
    "            continue\n",
    "        visits_codes_map.setdefault(hadm, set()).add(str(code))\n",
    "        code_counter[str(code)] += 1\n",
    "        if hadm not in visit_earliest_ts:\n",
    "            visit_earliest_ts[hadm] = ev.timestamp\n",
    "    if not visits_codes_map:\n",
    "        continue\n",
    "    ordered_hadm = sorted(visits_codes_map.keys(), key=lambda h: visit_earliest_ts.get(h))\n",
    "    visits_codes = [sorted(list(visits_codes_map[h])) for h in ordered_hadm]\n",
    "    if visits_codes:\n",
    "        patient_to_visits[pid] = visits_codes\n",
    "\n",
    "# Vocab\n",
    "codes_sorted = sorted(code_counter.keys())\n",
    "code_to_index = {c: i for i, c in enumerate(codes_sorted)}\n",
    "index_to_code = {i: c for c, i in code_to_index.items()}\n",
    "num_codes = len(code_to_index)\n",
    "\n",
    "# Splits\n",
    "eligible_ids = [pid for pid, seq in patient_to_visits.items() if len(seq) >= 2]\n",
    "train_ids, temp_ids = train_test_split(eligible_ids, test_size=0.2, random_state=SEED)\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=SEED)\n",
    "\n",
    "# Helpers reused later\n",
    "import torch\n",
    "\n",
    "def codes_to_multihot(codes, code_to_index, num_codes):\n",
    "    v = torch.zeros(num_codes, dtype=torch.float32)\n",
    "    for c in codes:\n",
    "        idx = code_to_index.get(c)\n",
    "        if idx is not None:\n",
    "            v[idx] = 1.0\n",
    "    return v\n",
    "\n",
    "# Build training examples (history -> next)\n",
    "def build_incidence(visits_codes, code_to_index, num_codes):\n",
    "    T = len(visits_codes)\n",
    "    P = torch.zeros((num_codes, T), dtype=torch.float32)\n",
    "    for j, codes in enumerate(visits_codes):\n",
    "        for c in codes:\n",
    "            idx = code_to_index.get(c)\n",
    "            if idx is not None:\n",
    "                P[idx, j] = 1.0\n",
    "    return P\n",
    "\n",
    "def build_examples(patient_ids):\n",
    "    ex = []\n",
    "    for pid in patient_ids:\n",
    "        seq = patient_to_visits[pid]\n",
    "        if len(seq) < 2:\n",
    "            continue\n",
    "        P = build_incidence(seq[:-1], code_to_index, num_codes)\n",
    "        y = codes_to_multihot(seq[-1], code_to_index, num_codes)\n",
    "        ex.append((P, y))\n",
    "    return ex\n",
    "\n",
    "train_ex = build_examples(train_ids)\n",
    "val_ex = build_examples(val_ids)\n",
    "test_ex = build_examples(test_ids)\n",
    "\n",
    "sample_pid = train_ids[0] if len(train_ids) > 0 else None\n",
    "print({\n",
    "    \"prepared\": True,\n",
    "    \"num_patients_seq>=2\": len(eligible_ids),\n",
    "    \"num_codes\": num_codes,\n",
    "    \"train_examples\": len(train_ex),\n",
    "    \"val_examples\": len(val_ex),\n",
    "    \"test_examples\": len(test_ex),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation Study: Removing Phenotype-Level Attention (Novel Extension)\n",
    "\n",
    "In the original SHy architecture, each phenotype \n",
    "ğ‘ˆ\n",
    "ğ‘˜\n",
    "U\n",
    "k\n",
    "\tâ€‹\n",
    "\n",
    " contributes to the final prediction through a learned attention vector \n",
    "ğ›¼\n",
    "âˆˆ\n",
    "ğ‘…\n",
    "ğ¾\n",
    "Î±âˆˆR\n",
    "K\n",
    ", allowing the model to upweight or downweight certain temporal phenotypes depending on the patient. This attention mechanism is central to SHyâ€™s interpretability and predictive power.\n",
    "\n",
    "However, the SHy paper does not include an ablation that removes this component entirely.\n",
    "To satisfy the requirement for a novel and implementable extension, we introduce the following ablation:\n",
    "\n",
    "Ablation Description\n",
    "\n",
    "We remove the phenotype attention mechanism and replace it with a simple uniform average over phenotype embeddings:\n",
    "\n",
    "ğ‘ˆ\n",
    "=\n",
    "1\n",
    "ğ¾\n",
    "âˆ‘\n",
    "ğ‘˜\n",
    "=\n",
    "1\n",
    "ğ¾\n",
    "ğ‘ˆ\n",
    "ğ‘˜\n",
    "U=\n",
    "K\n",
    "1\n",
    "\tâ€‹\n",
    "\n",
    "k=1\n",
    "âˆ‘\n",
    "K\n",
    "\tâ€‹\n",
    "\n",
    "U\n",
    "k\n",
    "\tâ€‹\n",
    "\n",
    "This isolates the importance of phenotype attention and tests whether SHy depends on it for predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 5, 'params_M': 1230976}\n"
     ]
    }
   ],
   "source": [
    "# Set K=5 and rebuild the model (phenotypes)\n",
    "CFG[\"K\"] = 5\n",
    "model = SHyModel(num_codes=num_codes, cfg=CFG).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CFG[\"lr\"])  # fresh optimizer for new model\n",
    "print({\n",
    "    \"K\": CFG[\"K\"],\n",
    "    \"params_M\": sum(p.numel() for p in model.parameters())\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHyNoAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Ablation model: same hypergraph + phenotypes, but\n",
    "    - removes visit-level attention\n",
    "    - removes phenotype self-attention\n",
    "    and instead:\n",
    "    - averages GRU hidden states over time\n",
    "    - averages phenotype embeddings to get a single representation\n",
    "    \"\"\"\n",
    "    def __init__(self, num_codes: int, cfg: Dict):\n",
    "        super().__init__()\n",
    "        self.num_codes = num_codes\n",
    "        self.d_c = cfg[\"d_c\"]\n",
    "        self.Z = cfg[\"Z\"]\n",
    "        self.K = cfg[\"K\"]\n",
    "        self.tau = cfg[\"tau\"]\n",
    "\n",
    "        self.emb = CodeEmbedding(num_codes, self.d_c)\n",
    "        self.mp_layers = nn.ModuleList([UniGINLayer(self.d_c) for _ in range(self.Z)])\n",
    "        self.phenos = PhenotypeExtractor(self.d_c, self.K)\n",
    "        self.gru = nn.GRU(self.d_c, cfg[\"d_hid\"], batch_first=True)\n",
    "        self.cls = nn.Linear(cfg[\"d_hid\"], num_codes)\n",
    "\n",
    "    def forward(self, P: torch.Tensor, label: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        P: [|C|, T]\n",
    "        label is unused (kept only for compatibility if you later want a label-dependent loss)\n",
    "        \"\"\"\n",
    "        # 1) Hypergraph message passing\n",
    "        M = self.emb().to(P.device)  # [|C|, d_c]\n",
    "        for layer in self.mp_layers:\n",
    "            M = layer(M, P)\n",
    "\n",
    "        # 2) Phenotype masks (same as main model)\n",
    "        masks = self.phenos(M, P, self.tau)  # [K, |C|, T]\n",
    "\n",
    "        U_list = []\n",
    "        logits_k = []\n",
    "\n",
    "        for k in range(self.K):\n",
    "            Psi_k = masks[k]  # [|C|, T]\n",
    "            Vk = (Psi_k.t() @ M)  # [T, d_c]\n",
    "\n",
    "            # GRU over visits\n",
    "            H, _ = self.gru(Vk.unsqueeze(0))  # [1, T, d_hid]\n",
    "            H = H.squeeze(0)                  # [T, d_hid]\n",
    "\n",
    "            # ABLATION: replace attention with simple mean pooling over time\n",
    "            Uk = H.mean(dim=0)                # [d_hid]\n",
    "            U_list.append(Uk)\n",
    "            logits_k.append(self.cls(Uk))     # [|C|]\n",
    "\n",
    "        # ABLATION: simple average over phenotypes (no self-attention)\n",
    "        U = torch.stack(U_list, dim=0)            # [K, d_hid]\n",
    "        alpha = torch.full((self.K,), 1.0 / self.K, device=P.device)  # uniform weights\n",
    "        logits_k = torch.stack(logits_k, dim=0)   # [K, |C|]\n",
    "        logits = (alpha.unsqueeze(-1) * logits_k).sum(dim=0)  # [|C|]\n",
    "\n",
    "        aux = {\"masks\": masks, \"alpha\": alpha}\n",
    "        return logits, aux\n",
    "\n",
    "        return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1, 'train_loss': 41.8961, 'val_loss': 0.0388}\n",
      "{'epoch': 2, 'train_loss': 0.0342, 'val_loss': 0.0301}\n",
      "{'epoch': 3, 'train_loss': 0.0182, 'val_loss': 0.0132}\n",
      "Test metrics: {'recall@10': 0.1677, 'recall@20': 0.2406, 'ndcg@10': 0.1774, 'ndcg@20': 0.1946}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recall@10': 0.16771691784089898,\n",
       " 'recall@20': 0.24060366977332334,\n",
       " 'ndcg@10': 0.17735649101388032,\n",
       " 'ndcg@20': 0.194557684870097}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablation_model = SHyNoAttention(\n",
    "    num_codes=num_codes,\n",
    "    cfg=CFG,\n",
    ")\n",
    "\n",
    "ablation_results = train_and_eval(\n",
    "    model=ablation_model,\n",
    "    train_examples=train_ex,\n",
    "    val_examples=val_ex,\n",
    "    test_examples=test_ex,\n",
    "    epochs=CFG[\"epochs\"], \n",
    ")\n",
    "\n",
    "ablation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "baseline = baseline_results   # full SHy-lite\n",
    "ablation = ablation_results   # no-attention ablation\n",
    "\n",
    "# Dict keys (exact names returned by your model)\n",
    "metric_keys = [\"recall@10\", \"recall@20\", \"ndcg@10\"]\n",
    "\n",
    "# Pretty labels for the x-axis\n",
    "metric_labels = [\"Recall@10\", \"Recall@20\", \"nDCG@10\"]\n",
    "\n",
    "baseline_vals = [baseline[k] for k in metric_keys]\n",
    "ablation_vals = [ablation[k] for k in metric_keys]\n",
    "\n",
    "x = range(len(metric_keys))\n",
    "width = 0.3\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar([i - width/2 for i in x], baseline_vals, width, label=\"Baseline SHy-lite\")\n",
    "plt.bar([i + width/2 for i in x], ablation_vals, width, label=\"No-attention Ablation\")\n",
    "\n",
    "plt.xticks(x, metric_labels)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Ablation Study: Removing Attention Mechanisms\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
