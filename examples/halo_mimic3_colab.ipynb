{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HALO Synthetic Data Generation for MIMIC-III\n",
    "\n",
    "This notebook trains the HALO (Hierarchical Autoregressive Language mOdel) on your MIMIC-III data and generates synthetic patients.\n",
    "\n",
    "## What You'll Need\n",
    "\n",
    "1. **MIMIC-III Access**: Download these files from PhysioNet:\n",
    "   - `ADMISSIONS.csv`\n",
    "   - `DIAGNOSES_ICD.csv`\n",
    "   - `PATIENTS.csv`\n",
    "   - `patient_ids.txt` (list of patient IDs, one per line)\n",
    "\n",
    "2. **Google Colab**: Free tier works, but GPU recommended (Runtime \u2192 Change runtime type \u2192 GPU)\n",
    "\n",
    "3. **Time**:\n",
    "   - Demo (5 epochs, 1K samples): ~20-30 min on GPU\n",
    "   - Production (80 epochs, 10K samples): ~6-10 hours on GPU\n",
    "\n",
    "## How It Works\n",
    "\n",
    "1. **Setup**: Install PyHealth and mount Google Drive\n",
    "2. **Upload Data**: Upload your MIMIC-III CSV files\n",
    "3. **Configure**: Set hyperparameters (epochs, batch size, etc.)\n",
    "4. **Train**: Train HALO model (checkpoints saved to Drive)\n",
    "5. **Generate**: Create synthetic patients using trained model\n",
    "6. **Download**: Get CSV file with synthetic data\n",
    "\n",
    "## Important Notes\n",
    "\n",
    "\u26a0\ufe0f **Colab Timeout**: Free Colab sessions timeout after 12 hours. For production training (80 epochs), consider:\n",
    "- Colab Pro for longer sessions\n",
    "- Running on your own GPU cluster using `examples/slurm/train_halo_mimic3.slurm`\n",
    "\n",
    "\ud83d\udcca **Demo vs Production**:\n",
    "- Demo defaults (5 epochs, 1K samples) let you test the pipeline quickly\n",
    "- Production settings (80 epochs, 10K samples) match the published HALO results\n",
    "\n",
    "## References\n",
    "\n",
    "- [HALO Paper](https://arxiv.org/abs/2406.16061)\n",
    "- [PyHealth Documentation](https://pyhealth.readthedocs.io/)\n",
    "- [MIMIC-III Access](https://physionet.org/content/mimiciii/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Install PyHealth from GitHub (gets latest HALO implementation)\n# For development/CI: set BRANCH to specific branch name (e.g., 'halo-pr-528')\n# For production: leave BRANCH as None to use main branch\nBRANCH = None  # Change to 'halo-pr-528' or other branch name for development\n\nif BRANCH:\n    install_url = f\"git+https://github.com/sunlabuiuc/PyHealth.git@{BRANCH}\"\n    print(f\"Installing PyHealth from branch '{BRANCH}'...\")\nelse:\n    install_url = \"git+https://github.com/sunlabuiuc/PyHealth.git\"\n    print(\"Installing PyHealth from main branch...\")\n\n!pip install -q {install_url}\nprint(\"\u2713 PyHealth installed successfully!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Import required libraries\nimport os\nimport sys\nimport torch\nimport pickle\nimport pandas as pd\nimport shutil\nfrom google.colab import drive, files\nimport ipywidgets as widgets\nfrom IPython.display import display, Markdown, HTML\n\nprint(\"\u2713 All libraries imported successfully!\")\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Mount Google Drive for persistent storage\nprint(\"Mounting Google Drive...\")\ndrive.mount('/content/drive')\nprint(\"\u2713 Google Drive mounted at /content/drive\")\n\n# Create directory structure in Drive\nbase_dir = '/content/drive/MyDrive/HALO_Training'\ndata_dir = f'{base_dir}/data'\ncheckpoint_dir = f'{base_dir}/checkpoints'\npkl_data_dir = f'{base_dir}/pkl_data'\noutput_dir = f'{base_dir}/output'\n\nfor dir_path in [base_dir, data_dir, checkpoint_dir, pkl_data_dir, output_dir]:\n    os.makedirs(dir_path, exist_ok=True)\n\nprint(f\"\\n\u2713 Directory structure created:\")\nprint(f\"  Base: {base_dir}\")\nprint(f\"  Data: {data_dir}\")\nprint(f\"  Checkpoints: {checkpoint_dir}\")\nprint(f\"  Vocabulary: {pkl_data_dir}\")\nprint(f\"  Output: {output_dir}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Data Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 6. Results & Download"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}