{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyHealth Datasets Overview\n",
    "\n",
    "This notebook provides an overview of all datasets supported in PyHealth. For each dataset, we include:\n",
    "- **Description**: What the dataset contains.\n",
    "- **Source/Link**: Where to find the original data.\n",
    "- **Download Method**: How to obtain the data.\n",
    "- **Restrictions**: Any access requirements or limitations.\n",
    "- **Example Usage**: Code to load the dataset in PyHealth.\n",
    "\n",
    "**Note**: Many datasets require accounts, credentials, or compliance with data use agreements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MIMIC-III\n",
    "\n",
    "**Description**: A large dataset of de-identified health records from ICU patients at Beth Israel Deaconess Medical Center (2001-2012). Includes demographics, vital signs, lab results, medications, and more.\n",
    "\n",
    "**Source/Link**: https://physionet.org/content/mimiciii/1.4/\n",
    "\n",
    "**Download Method**:\n",
    "- Create PhysioNet account and complete HIPAA training.\n",
    "- Download: `wget -r -N -c -np --user [USERNAME] --ask-password https://physionet.org/files/mimiciii/1.4/`\n",
    "- Demo (no auth): `wget -r -N -c -np https://physionet.org/files/mimiciii-demo/1.4/`\n",
    "\n",
    "**Restrictions**: Requires PhysioNet account, HIPAA certification, and data use agreement. ~40GB.\n",
    "\n",
    "**Example Usage**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No config path provided, using default config\n",
      "Initializing mimic3 dataset from https://physionet.org/files/mimiciii-demo/1.4/ (dev mode: True)\n",
      "Scanning table: patients from https://physionet.org/files/mimiciii-demo/1.4/PATIENTS.csv.gz\n",
      "Original path does not exist. Using alternative: https://physionet.org/files/mimiciii-demo/1.4/PATIENTS.csv\n",
      "Scanning table: admissions from https://physionet.org/files/mimiciii-demo/1.4/ADMISSIONS.csv.gz\n",
      "Original path does not exist. Using alternative: https://physionet.org/files/mimiciii-demo/1.4/ADMISSIONS.csv\n",
      "Scanning table: icustays from https://physionet.org/files/mimiciii-demo/1.4/ICUSTAYS.csv.gz\n",
      "Original path does not exist. Using alternative: https://physionet.org/files/mimiciii-demo/1.4/ICUSTAYS.csv\n",
      "Scanning table: diagnoses_icd from https://physionet.org/files/mimiciii-demo/1.4/DIAGNOSES_ICD.csv.gz\n",
      "Original path does not exist. Using alternative: https://physionet.org/files/mimiciii-demo/1.4/DIAGNOSES_ICD.csv\n",
      "Joining with table: https://physionet.org/files/mimiciii-demo/1.4/ADMISSIONS.csv.gz\n",
      "Original path does not exist. Using alternative: https://physionet.org/files/mimiciii-demo/1.4/ADMISSIONS.csv\n",
      "Scanning table: prescriptions from https://physionet.org/files/mimiciii-demo/1.4/PRESCRIPTIONS.csv.gz\n",
      "Original path does not exist. Using alternative: https://physionet.org/files/mimiciii-demo/1.4/PRESCRIPTIONS.csv\n",
      "Joining with table: https://physionet.org/files/mimiciii-demo/1.4/ADMISSIONS.csv.gz\n",
      "Original path does not exist. Using alternative: https://physionet.org/files/mimiciii-demo/1.4/ADMISSIONS.csv\n"
     ]
    }
   ],
   "source": [
    "from pyhealth.datasets import MIMIC3Dataset\n",
    "\n",
    "# Download Demo MIMIC3 dataset\n",
    "mimic3_demo = MIMIC3Dataset(\n",
    "    root=\"https://physionet.org/files/mimiciii-demo/1.4/\",\n",
    "    tables=[\"DIAGNOSES_ICD\", \"PRESCRIPTIONS\"],\n",
    "    dev=True  # Use dev mode for small subset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting global event dataframe...\n",
      "Dev mode enabled: limiting to 1000 patients\n",
      "Collected dataframe with shape: (12524, 46)\n",
      "Dataset: mimic3\n",
      "Dev mode: True\n",
      "Number of patients: 100\n",
      "Number of events: 12524\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(mimic3_demo.stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MIMIC-IV\n",
    "\n",
    "**Description**: Updated version of MIMIC-III with EHR, clinical notes, and chest X-rays from 2008-2019.\n",
    "\n",
    "**Source/Link**: https://physionet.org/content/mimiciv/0.4/\n",
    "\n",
    "**Download Method**:\n",
    "- PhysioNet account required.\n",
    "- Download: `wget -r -N -c -np --user [USERNAME] --ask-password https://physionet.org/files/mimiciv/2.2/`\n",
    "- Demo: `wget -r -N -c -np https://physionet.org/files/mimic-iv-demo/2.2/`\n",
    "\n",
    "**Restrictions**: PhysioNet account, HIPAA training. ~200GB.\n",
    "\n",
    "**Example Usage**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage Starting MIMIC4Dataset init: 806.7 MB\n",
      "Initializing MIMIC4EHRDataset with tables: ['diagnoses_icd', 'prescriptions'] (dev mode: True)\n",
      "Using default EHR config: /home/ubuntu/PyHealth/pyhealth/datasets/configs/mimic4_ehr.yaml\n",
      "Memory usage Before initializing mimic4_ehr: 806.7 MB\n",
      "Initializing mimic4_ehr dataset from https://physionet.org/files/mimic-iv-demo/2.2/ (dev mode: False)\n",
      "Scanning table: diagnoses_icd from https://physionet.org/files/mimic-iv-demo/2.2/hosp/diagnoses_icd.csv.gz\n",
      "Joining with table: https://physionet.org/files/mimic-iv-demo/2.2/hosp/admissions.csv.gz\n",
      "Scanning table: prescriptions from https://physionet.org/files/mimic-iv-demo/2.2/hosp/prescriptions.csv.gz\n",
      "Scanning table: patients from https://physionet.org/files/mimic-iv-demo/2.2/hosp/patients.csv.gz\n",
      "Scanning table: admissions from https://physionet.org/files/mimic-iv-demo/2.2/hosp/admissions.csv.gz\n",
      "Scanning table: icustays from https://physionet.org/files/mimic-iv-demo/2.2/icu/icustays.csv.gz\n",
      "Memory usage After initializing mimic4_ehr: 806.7 MB\n",
      "Memory usage After EHR dataset initialization: 806.7 MB\n",
      "Memory usage Before combining data: 806.7 MB\n",
      "Combining data from ehr dataset\n",
      "Creating combined dataframe\n",
      "Memory usage After combining data: 806.7 MB\n",
      "Memory usage Completed MIMIC4Dataset init: 806.7 MB\n"
     ]
    }
   ],
   "source": [
    "from pyhealth.datasets import MIMIC4Dataset\n",
    "\n",
    "# EHR only\n",
    "mimic4_demo = MIMIC4Dataset(\n",
    "    ehr_root=\"https://physionet.org/files/mimic-iv-demo/2.2/\",\n",
    "    ehr_tables=[\"diagnoses_icd\", \"prescriptions\"],\n",
    "    dev=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting global event dataframe...\n",
      "Dev mode enabled: limiting to 1000 patients\n",
      "Collected dataframe with shape: (23108, 34)\n",
      "Dataset: mimic4\n",
      "Dev mode: True\n",
      "Number of patients: 100\n",
      "Number of events: 23108\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(mimic4_demo.stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. eICU\n",
    "\n",
    "**Description**: Multi-center ICU database from US hospitals (2014-2015), including demographics, diagnoses, treatments, labs, and vitals.\n",
    "\n",
    "**Source/Link**: https://eicu-crd.mit.edu/\n",
    "\n",
    "**Download Method**:\n",
    "- Register and agree to terms.\n",
    "- Download: `wget -r -N -c -np --user [USERNAME] --ask-password https://physionet.org/files/eicu-crd/2.0/`\n",
    "\n",
    "**Restrictions**: Account required, data use agreement. ~10GB.\n",
    "\n",
    "**Example Usage**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.datasets import eICUDataset\n",
    "\n",
    "# No demo is available for EICU, so this will be empty unless you have the data locally\n",
    "eicu = eICUDataset(\n",
    "    root=\"/path/to/eicu-crd/2.0\",\n",
    "    tables=[\"diagnosis\", \"medication\"],\n",
    "    dev=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyhealth.datasets.eicu.eICUDataset at 0x76e5605c3650>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eicu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Datasets in OMOP format\n",
    "\n",
    "**Description**: Observational Medical Outcomes Partnership Common Data Model (OMOP-CDM) is a standard for structuring healthcare data. PyHealth supports datasets formatted in OMOP-CDM (e.g., from various sources like EHR systems).\n",
    "\n",
    "**Source/Link**: https://www.ohdsi.org/data-standardization/the-common-data-model/\n",
    "\n",
    "**Download Method**: Varies by source; often requires partnerships or custom access to OMOP-formatted data.\n",
    "\n",
    "**Restrictions**: Institutional access often required.\n",
    "\n",
    "**Example Usage**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from pyhealth.datasets import OMOPDataset\n",
    "\n",
    "dataset = OMOPDataset(\n",
    "    root=\"/path/to/omop/data\",\n",
    "    tables=[\"condition_occurrence\", \"drug_exposure\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sleep-EDF\n",
    "\n",
    "**Description**: Sleep EEG recordings for sleep staging.\n",
    "\n",
    "**Source/Link**: https://physionet.org/content/sleep-edfx/1.0.0/\n",
    "\n",
    "**Download Method**: `wget -r -N -c -np https://physionet.org/files/sleep-edfx/1.0.0/`\n",
    "\n",
    "**Restrictions**: Publicly available, no auth.\n",
    "\n",
    "**Example Usage**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from pyhealth.datasets import SleepEDFDataset\n",
    "\n",
    "dataset = SleepEDFDataset(\n",
    "    root=\"/path/to/sleep-edfx\",\n",
    "    dev=True\n",
    ")\n",
    "print(dataset.stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. SHHS\n",
    "\n",
    "**Description**: Sleep Heart Health Study polysomnography data.\n",
    "\n",
    "**Source/Link**: https://sleepdata.org/datasets/shhs\n",
    "\n",
    "**Download Method**: Register and download from site.\n",
    "\n",
    "**Restrictions**: Account required.\n",
    "\n",
    "**Example Usage**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from pyhealth.datasets import SHHSDataset\n",
    "\n",
    "dataset = SHHSDataset(\n",
    "    root=\"/path/to/shhs\",\n",
    "    dev=True\n",
    ")\n",
    "print(f\"Loaded {len(dataset.patients)} patients.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ISRUC\n",
    "\n",
    "**Description**: ISRUC-SLEEP dataset for sleep staging.\n",
    "\n",
    "**Source/Link**: https://sleeptight.isr.uc.pt/?page_id=48\n",
    "\n",
    "**Download Method**: Download from site.\n",
    "\n",
    "**Restrictions**: Public.\n",
    "\n",
    "**Example Usage**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from pyhealth.datasets import ISRUCDataset\n",
    "\n",
    "dataset = ISRUCDataset(\n",
    "    root=\"/path/to/isruc\",\n",
    "    dev=True\n",
    ")\n",
    "print(f\"Loaded {len(dataset.patients)} patients.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cardiology (PhysioNet Challenge 2020)\n",
    "\n",
    "**Description**: ECG data from multiple sources for arrhythmia detection.\n",
    "\n",
    "**Source/Link**: https://physionet.org/content/challenge-2020/1.0.2/\n",
    "\n",
    "**Download Method**: `wget -r -N -c -np https://physionet.org/files/challenge-2020/1.0.2/`\n",
    "\n",
    "**Restrictions**: Public.\n",
    "\n",
    "**Example Usage**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyhealth.datasets.cardiology.CardiologyDataset object at 0x76e557bf53d0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyhealth.datasets import CardiologyDataset\n",
    "\n",
    "cardiology = CardiologyDataset(\n",
    "    #root=\"/path/to/challenge-2020\",\n",
    "    root = \"https://physionet.org/files/challenge-2020/1.0.2/\",\n",
    "    dev=True\n",
    ")\n",
    "print(cardiology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. COVID-19 CXR\n",
    "\n",
    "**Description**: Chest X-ray images for COVID-19 classification.\n",
    "\n",
    "**Source/Link**: Custom or public sources (check PyHealth docs).\n",
    "\n",
    "**Download Method**: Varies; often from Kaggle or GitHub.\n",
    "\n",
    "**Restrictions**: Public datasets.\n",
    "\n",
    "**Example Usage**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from pyhealth.datasets import COVID19CXRDataset\n",
    "\n",
    "dataset = COVID19CXRDataset(\n",
    "    root=\"/path/to/covid19-cxr\",\n",
    "    dev=True\n",
    ")\n",
    "print(f\"Loaded {len(dataset.patients)} patients.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Sample Dataset (Test/Synthetic)\n",
    "\n",
    "**Description**: Synthetic dataset for testing and development, with customizable samples.\n",
    "\n",
    "**Source/Link**: Built-in to PyHealth (no external source).\n",
    "\n",
    "**Download Method**: No download needed; created programmatically.\n",
    "\n",
    "**Restrictions**: None; for testing only.\n",
    "\n",
    "**Example Usage**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInit signature:\u001b[39m\n",
      "SampleDataset(\n",
      "    samples: List[Dict],\n",
      "    input_schema: Dict[str, Union[str, Type[pyhealth.processors.base_processor.FeatureProcessor]]],\n",
      "    output_schema: Dict[str, Union[str, Type[pyhealth.processors.base_processor.FeatureProcessor]]],\n",
      "    dataset_name: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    task_name: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    input_processors: Optional[Dict[str, pyhealth.processors.base_processor.FeatureProcessor]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    output_processors: Optional[Dict[str, pyhealth.processors.base_processor.FeatureProcessor]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      ") -> \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mDocstring:\u001b[39m     \n",
      "Sample dataset class for handling and processing data samples.\n",
      "\n",
      "Attributes:\n",
      "    samples (List[Dict]): List of data samples.\n",
      "    input_schema (Dict[str, Union[str, Type[FeatureProcessor], Tuple[Union[str, Type[FeatureProcessor]], Dict[str, Any]]]]):\n",
      "        Schema for input data. Values can be string aliases, processor classes, or tuples of (spec, kwargs_dict).\n",
      "    output_schema (Dict[str, Union[str, Type[FeatureProcessor], Tuple[Union[str, Type[FeatureProcessor]], Dict[str, Any]]]]):\n",
      "        Schema for output data. Values can be string aliases, processor classes, or tuples of (spec, kwargs_dict).\n",
      "    dataset_name (Optional[str]): Name of the dataset.\n",
      "    task_name (Optional[str]): Name of the task.\n",
      "\u001b[31mInit docstring:\u001b[39m\n",
      "Initializes the SampleDataset with samples and schemas.\n",
      "\n",
      "Args:\n",
      "    samples (List[Dict]): List of data samples.\n",
      "    input_schema (Dict[str, Union[str, Type[FeatureProcessor], Tuple[Union[str, Type[FeatureProcessor]], Dict[str, Any]]]]):\n",
      "        Schema for input data. Values can be string aliases, processor classes, or tuples of (spec, kwargs_dict) for instantiation.\n",
      "    output_schema (Dict[str, Union[str, Type[FeatureProcessor], Tuple[Union[str, Type[FeatureProcessor]], Dict[str, Any]]]]):\n",
      "        Schema for output data. Values can be string aliases, processor classes, or tuples of (spec, kwargs_dict) for instantiation.\n",
      "    dataset_name (Optional[str], optional): Name of the dataset.\n",
      "        Defaults to None.\n",
      "    task_name (Optional[str], optional): Name of the task.\n",
      "        Defaults to None.\n",
      "    input_processors (Optional[Dict[str, FeatureProcessor]],\n",
      "        optional): Pre-fitted input processors. If provided, these\n",
      "        will be used instead of creating new ones from input_schema.\n",
      "        Defaults to None.\n",
      "    output_processors (Optional[Dict[str, FeatureProcessor]],\n",
      "        optional): Pre-fitted output processors. If provided, these\n",
      "        will be used instead of creating new ones from output_schema.\n",
      "        Defaults to None.\n",
      "\u001b[31mFile:\u001b[39m           ~/PyHealth/pyhealth/datasets/sample_dataset.py\n",
      "\u001b[31mType:\u001b[39m           type\n",
      "\u001b[31mSubclasses:\u001b[39m     "
     ]
    }
   ],
   "source": [
    "SampleDataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label label vocab: {0: 0, 1: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Create synthetic samples\u001b[39;00m\n\u001b[32m      4\u001b[39m samples = [\n\u001b[32m      5\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mpatient_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mconditions\u001b[39m\u001b[33m\"\u001b[39m: [[\u001b[33m\"\u001b[39m\u001b[33mC001\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mC002\u001b[39m\u001b[33m\"\u001b[39m]], \u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0\u001b[39m},\n\u001b[32m      6\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mpatient_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mconditions\u001b[39m\u001b[33m\"\u001b[39m: [[\u001b[33m\"\u001b[39m\u001b[33mC003\u001b[39m\u001b[33m\"\u001b[39m]], \u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m}\n\u001b[32m      7\u001b[39m ]\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m dataset = \u001b[43mSampleDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m=\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_schema\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconditions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msequence\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_schema\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbinary\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m synthetic samples.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PyHealth/pyhealth/datasets/sample_dataset.py:88\u001b[39m, in \u001b[36mSampleDataset.__init__\u001b[39m\u001b[34m(self, samples, input_schema, output_schema, dataset_name, task_name, input_processors, output_processors)\u001b[39m\n\u001b[32m     85\u001b[39m         \u001b[38;5;28mself\u001b[39m.record_to_index[record_id].append(i)\n\u001b[32m     87\u001b[39m \u001b[38;5;28mself\u001b[39m.validate()\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PyHealth/pyhealth/datasets/sample_dataset.py:150\u001b[39m, in \u001b[36mSampleDataset.build\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m sample.items():\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.input_processors:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m         sample[k] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_processors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_processors:\n\u001b[32m    152\u001b[39m         sample[k] = \u001b[38;5;28mself\u001b[39m.output_processors[k].process(v)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PyHealth/pyhealth/processors/sequence_processor.py:38\u001b[39m, in \u001b[36mSequenceProcessor.process\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m     36\u001b[39m     indices.append(\u001b[38;5;28mself\u001b[39m.code_vocab[\u001b[33m\"\u001b[39m\u001b[33m<unk>\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcode_vocab\u001b[49m:\n\u001b[32m     39\u001b[39m         \u001b[38;5;28mself\u001b[39m.code_vocab[token] = \u001b[38;5;28mself\u001b[39m._next_index\n\u001b[32m     40\u001b[39m         \u001b[38;5;28mself\u001b[39m._next_index += \u001b[32m1\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "from pyhealth.datasets import SampleDataset\n",
    "\n",
    "# Create synthetic samples\n",
    "samples = [\n",
    "    {\"patient_id\": \"1\", \"conditions\": [\"C001\", \"C002\"], \"label\": 0},\n",
    "    {\"patient_id\": \"2\", \"conditions\": [\"C003\"], \"label\": 1}\n",
    "]\n",
    "\n",
    "dataset = SampleDataset(\n",
    "    samples=samples,\n",
    "    input_schema={\"conditions\": \"sequence\"},\n",
    "    output_schema={\"label\": \"binary\"}\n",
    ")\n",
    "print(f\"Loaded {len(dataset)} synthetic samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. BMD-HS\n",
    "\n",
    "**Description**: Curated collection of phonocardiogram (PCG/heart-sound) recordings desinged for automated cardiovascular disease research. \n",
    "\n",
    "**Source/Link**: Custom or public sources. \n",
    "    https://github.com/sani002/BMD-HS-Dataset\n",
    "\n",
    "\n",
    "**Download Method**: Varies; often from Kaggle or GitHub.\n",
    "\n",
    "**Restrictions**: Cite the following if used. \n",
    "    Ali, S. N., Zahin, A., Shuvo, S. B., Nizam, N. B., Nuhash, S. I. S. K., Razin, S. S.,\n",
    "    Sani, S. M. S., Rahman, F., Nizam, N. B., Azam, F. B., Hossen, R., Ohab, S., Noor, N., & Hasan, T. (2024).\n",
    "    BUET Multi-disease Heart Sound Dataset: A Comprehensive Auscultation Dataset for Developing\n",
    "    Computer-Aided Diagnostic Systems. arXiv:2409.00724. https://arxiv.org/abs/2409.00724\n",
    "**Example Usage**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. ClinVar\n",
    "\n",
    "**Description**: ClinVar is a freely accessible, public archive of reports of the relationships\n",
    "among human variations and phenotypes, with supporting evidence.\n",
    "\n",
    "**Source/Link**: https://ftp.ncbi.nlm.nih.gov/pub/clinvar/\n",
    "\n",
    "**Download Method**: Download from site.\n",
    "\n",
    "**Restrictions**: None. Public data.\n",
    "\n",
    "**Example Usage**: Variant pathogenicity prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No config path provided, using default config\n",
      "Preparing ClinVar metadata...\n",
      "No raw ClinVar file found in https://ftp.ncbi.nlm.nih.gov/pub/clinvar/. Please download from https://ftp.ncbi.nlm.nih.gov/pub/clinvar/ and place variant_summary.txt in the root directory.\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyhealth\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ClinVarDataset\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m clinvar = \u001b[43mClinVarDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://ftp.ncbi.nlm.nih.gov/pub/clinvar/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdev\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m clinvar.stats()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PyHealth/pyhealth/datasets/clinvar.py:65\u001b[39m, in \u001b[36mClinVarDataset.__init__\u001b[39m\u001b[34m(self, root, tables, dataset_name, config_path, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(pyhealth_csv):\n\u001b[32m     64\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mPreparing ClinVar metadata...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m default_tables = [\u001b[33m\"\u001b[39m\u001b[33mvariants\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     68\u001b[39m tables = default_tables + (tables \u001b[38;5;129;01mor\u001b[39;00m [])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PyHealth/pyhealth/datasets/clinvar.py:121\u001b[39m, in \u001b[36mClinVarDataset.prepare_metadata\u001b[39m\u001b[34m(root)\u001b[39m\n\u001b[32m    103\u001b[39m     logger.warning(\n\u001b[32m    104\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo raw ClinVar file found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    105\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease download from https://ftp.ncbi.nlm.nih.gov/pub/clinvar/ \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    106\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mand place variant_summary.txt in the root directory.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    107\u001b[39m     )\n\u001b[32m    108\u001b[39m     \u001b[38;5;66;03m# Create empty placeholder\u001b[39;00m\n\u001b[32m    109\u001b[39m     \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgene_symbol\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclinical_significance\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreview_status\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mchromosome\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mposition\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreference_allele\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43malternate_allele\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvariant_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43massembly\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclinvar-pyhealth.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    124\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing ClinVar file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mraw_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/PYH/lib/python3.11/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/PYH/lib/python3.11/site-packages/pandas/core/generic.py:3989\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3978\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3980\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3981\u001b[39m     frame=df,\n\u001b[32m   3982\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3986\u001b[39m     decimal=decimal,\n\u001b[32m   3987\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3989\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4006\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/PYH/lib/python3.11/site-packages/pandas/io/formats/format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/PYH/lib/python3.11/site-packages/pandas/io/formats/csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/PYH/lib/python3.11/site-packages/pandas/io/common.py:728\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    725\u001b[39m     codecs.lookup_error(errors)\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m ioargs = \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m handle = ioargs.filepath_or_buffer\n\u001b[32m    737\u001b[39m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/PYH/lib/python3.11/site-packages/pandas/io/common.py:384\u001b[39m, in \u001b[36m_get_filepath_or_buffer\u001b[39m\u001b[34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[32m    383\u001b[39m req_info = urllib.request.Request(filepath_or_buffer, headers=storage_options)\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[32m    385\u001b[39m     content_encoding = req.headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Encoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding == \u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/PYH/lib/python3.11/site-packages/pandas/io/common.py:289\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[33;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03mthe stdlib.\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrequest\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/PYH/lib/python3.11/urllib/request.py:216\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    215\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/PYH/lib/python3.11/urllib/request.py:525\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    524\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/PYH/lib/python3.11/urllib/request.py:634\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    631\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    632\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/PYH/lib/python3.11/urllib/request.py:563\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    561\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    562\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/PYH/lib/python3.11/urllib/request.py:496\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    495\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    498\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/PYH/lib/python3.11/urllib/request.py:643\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "from pyhealth.datasets import ClinVarDataset\n",
    "clinvar = ClinVarDataset(\n",
    "    root=\"https://ftp.ncbi.nlm.nih.gov/pub/clinvar/\",\n",
    "    dev=True\n",
    ")\n",
    "clinvar.stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. DREAMT\n",
    "\n",
    "**Description**: DREAMT includes wrist-based wearable and polysomnography (PSG) sleep data from 100 participants\n",
    "recruited from the Duke University Health System (DUHS) Sleep Disorder Lab. This includes \n",
    "wearable signals, PSG signals, sleep labels, and clinical data related to sleep health and disorders. \n",
    "\n",
    "**Source/Link**: https://physionet.org/content/dreamt/\n",
    "\n",
    "**Download Method**: `wget -r -N -c -np https://physionet.org/content/dreamt/2.1/`\n",
    "\n",
    "**Restrictions**: None. Public data.\n",
    "\n",
    "**Example Usage**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. OMOP\n",
    "\n",
    "**Description**: The Observational Medical Outcomes Partnership (OMOP) Common Data\n",
    "Model (CDM) is an open community data standard, designed to\n",
    "standardize the structure and content of observational data.\n",
    "\n",
    "**Source/Link**: https://www.ohdsi.org/data-standardization/\n",
    "\n",
    "**Download Method**: Download from site.\n",
    "\n",
    "**Restrictions**: None. Public data.\n",
    "\n",
    "**Example Usage**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Datasets\n",
    "\n",
    "- **EHRShot**: Benchmark dataset for EHR tasks.\n",
    "- **Medical Transcriptions**: Text data for NLP.\n",
    "- **TUAB/TUEV**: EEG datasets from Temple University.\n",
    "- **MIMIC-Extract**: Processed MIMIC data.\n",
    "\n",
    "For full details, check the PyHealth documentation and dataset source links."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
