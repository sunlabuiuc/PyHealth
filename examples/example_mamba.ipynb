{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb8b8ad6",
   "metadata": {},
   "source": [
    "# Mamba on MIMIC-IV (Demo)\n",
    "This minimal walkthrough uses PyHealth's built-in utilities to train the PyHealth Mamba model on a two new MIMIC-IV tasks: mortality prediction within one month, and binary LOS prediction over one week. It also includes a demonstration of using LR schedulers with PyHealth's Trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f372eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.datasets import MIMIC4Dataset, get_dataloader, split_by_sample\n",
    "from pyhealth.tasks import MortalityPrediction31DaysMIMIC4, BinaryLengthOfStayPredictionMIMIC4\n",
    "from pyhealth.trainer import Trainer\n",
    "from pyhealth.models import Mamba\n",
    "\n",
    "MIMIC4_PATH = \"../datasets/mimic-iv-2.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d811ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MIMIC4Dataset(\n",
    "    ehr_root=MIMIC4_PATH,\n",
    "    ehr_tables=[\"patients\", \"admissions\", \"diagnoses_icd\", \"procedures_icd\", \"prescriptions\"],\n",
    "    dev=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a460d43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting task BinaryLengthOfStayPredictionMIMIC4 for mimic4 base dataset...\n",
      "Generating samples with 1 worker(s)...\n",
      "Collecting global event dataframe...\n",
      "Dev mode enabled: limiting to 1000 patients\n",
      "Collected dataframe with shape: (76949, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples for BinaryLengthOfStayPredictionMIMIC4 with 1 worker: 100%|██████████| 1000/1000 [00:02<00:00, 368.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching samples to ../test_cache_mamba_los/BinaryLengthOfStayPredictionMIMIC4.parquet\n",
      "Successfully cached 452 samples\n",
      "Label length_of_stay vocab: {0: 0, 1: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing samples: 100%|██████████| 452/452 [00:00<00:00, 56674.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 452 samples for task BinaryLengthOfStayPredictionMIMIC4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TASK = \"length_of_stay_prediction\"\n",
    "\n",
    "if TASK == \"length_of_stay_prediction\":\n",
    "    sample_dataset = dataset.set_task(\n",
    "        task=BinaryLengthOfStayPredictionMIMIC4(),\n",
    "        cache_dir=\"../test_cache_mamba_los\",\n",
    "    )\n",
    "elif TASK == \"mortality_prediction\":\n",
    "    sample_dataset = dataset.set_task(\n",
    "        task=MortalityPrediction31DaysMIMIC4(),\n",
    "        cache_dir=\"../test_cache_mamba_mort\",\n",
    "    )\n",
    "train_dataset, val_dataset, test_dataset = split_by_sample(sample_dataset, ratios=[0.7, 0.1, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7e9a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_dataloader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = get_dataloader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = get_dataloader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f80df975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mamba(\n",
      "  (embedding_model): EmbeddingModel(embedding_layers=ModuleDict(\n",
      "    (conditions): Embedding(1766, 128, padding_idx=0)\n",
      "    (procedures): Embedding(562, 128, padding_idx=0)\n",
      "    (drugs): Embedding(768, 128, padding_idx=0)\n",
      "  ))\n",
      "  (mamba_layers): ModuleDict(\n",
      "    (conditions): MambaLayers(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x ResidualBlock(\n",
      "          (mixer): MambaBlock(\n",
      "            (in_proj): Linear(in_features=128, out_features=512, bias=False)\n",
      "            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)\n",
      "            (x_proj): Linear(in_features=256, out_features=40, bias=False)\n",
      "            (dt_proj): Linear(in_features=8, out_features=256, bias=True)\n",
      "            (out_proj): Linear(in_features=256, out_features=128, bias=False)\n",
      "          )\n",
      "          (norm): RMSNorm()\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (procedures): MambaLayers(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x ResidualBlock(\n",
      "          (mixer): MambaBlock(\n",
      "            (in_proj): Linear(in_features=128, out_features=512, bias=False)\n",
      "            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)\n",
      "            (x_proj): Linear(in_features=256, out_features=40, bias=False)\n",
      "            (dt_proj): Linear(in_features=8, out_features=256, bias=True)\n",
      "            (out_proj): Linear(in_features=256, out_features=128, bias=False)\n",
      "          )\n",
      "          (norm): RMSNorm()\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drugs): MambaLayers(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x ResidualBlock(\n",
      "          (mixer): MambaBlock(\n",
      "            (in_proj): Linear(in_features=128, out_features=512, bias=False)\n",
      "            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)\n",
      "            (x_proj): Linear(in_features=256, out_features=40, bias=False)\n",
      "            (dt_proj): Linear(in_features=8, out_features=256, bias=True)\n",
      "            (out_proj): Linear(in_features=256, out_features=128, bias=False)\n",
      "          )\n",
      "          (norm): RMSNorm()\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=384, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: ['roc_auc', 'pr_auc']\n",
      "Device: cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Mamba(dataset=sample_dataset, embedding_dim=128, num_layers=2, dropout=0.1)\n",
    "trainer = Trainer(model=model, metrics=[\"roc_auc\", \"pr_auc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a4c464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builder function for creating an SequentialLR scheduler with linear warmup and decay\n",
    "from torch.optim.lr_scheduler import LinearLR, SequentialLR\n",
    "\n",
    "def build_linear_scheduler_with_warmup_and_decay(optimizer, n_steps, warmup_ratio=0.1, decay_ratio=0.9):\n",
    "    n_warmup_steps = int(warmup_ratio * n_steps)\n",
    "    n_decay_steps = int(decay_ratio * n_steps)\n",
    "\n",
    "    warmup = LinearLR(\n",
    "        optimizer,\n",
    "        start_factor=0.01,\n",
    "        end_factor=1.0,\n",
    "        total_iters=n_warmup_steps,\n",
    "    )\n",
    "    decay = LinearLR(\n",
    "        optimizer,\n",
    "        start_factor=1.0,\n",
    "        end_factor=0.01,\n",
    "        total_iters=n_decay_steps,\n",
    "    )\n",
    "    scheduler = SequentialLR(\n",
    "        optimizer=optimizer,\n",
    "        schedulers=[warmup, decay],\n",
    "        milestones=[n_warmup_steps],\n",
    "    )\n",
    "\n",
    "    return scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f808fb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.adam.Adam'>\n",
      "Optimizer params: {'lr': 0.0001}\n",
      "Scheduler: <function build_linear_scheduler_with_warmup_and_decay at 0x7ff012e880e0>\n",
      "Scheduler params: {'n_steps': 50, 'warmup_ratio': 0.1, 'decay_ratio': 0.9}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7ff01354e180>\n",
      "Monitor: roc_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 5\n",
      "Patience: None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 5: 100%|██████████| 10/10 [00:00<00:00, 15.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-10 ---\n",
      "loss: 0.7576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 2/2 [00:00<00:00, 96.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-0, step-10 ---\n",
      "roc_auc: 0.5000\n",
      "pr_auc: 0.3516\n",
      "loss: 0.7141\n",
      "New best roc_auc score (0.5000) at epoch-0, step-10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 / 5: 100%|██████████| 10/10 [00:00<00:00, 20.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-20 ---\n",
      "loss: 0.7315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 2/2 [00:00<00:00, 111.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-1, step-20 ---\n",
      "roc_auc: 0.5086\n",
      "pr_auc: 0.3547\n",
      "loss: 0.7094\n",
      "New best roc_auc score (0.5086) at epoch-1, step-20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 / 5: 100%|██████████| 10/10 [00:00<00:00, 21.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-30 ---\n",
      "loss: 0.7209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 2/2 [00:00<00:00, 104.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-2, step-30 ---\n",
      "roc_auc: 0.5114\n",
      "pr_auc: 0.3561\n",
      "loss: 0.7059\n",
      "New best roc_auc score (0.5114) at epoch-2, step-30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 / 5: 100%|██████████| 10/10 [00:00<00:00, 19.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-40 ---\n",
      "loss: 0.7052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 2/2 [00:00<00:00, 94.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-3, step-40 ---\n",
      "roc_auc: 0.5114\n",
      "pr_auc: 0.3561\n",
      "loss: 0.7040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 / 5: 100%|██████████| 10/10 [00:00<00:00, 20.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-50 ---\n",
      "loss: 0.7094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 2/2 [00:00<00:00, 98.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-4, step-50 ---\n",
      "roc_auc: 0.5114\n",
      "pr_auc: 0.3561\n",
      "loss: 0.7032\n",
      "Loaded best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "trainer.train(\n",
    "    train_dataloader=train_loader,\n",
    "    val_dataloader=val_loader,\n",
    "    epochs=epochs,\n",
    "    monitor=\"roc_auc\",\n",
    "    optimizer_params={\"lr\": 1e-4},\n",
    "    scheduler_class_or_fn=build_linear_scheduler_with_warmup_and_decay,\n",
    "    scheduler_params={\"n_steps\": len(train_loader) * epochs, \"warmup_ratio\": 0.1, \"decay_ratio\": 0.9},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0bce3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 3/3 [00:00<00:00, 101.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.37758346581875996,\n",
       " 'pr_auc': 0.16746778796751344,\n",
       " 'loss': 0.7669918338457743}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
