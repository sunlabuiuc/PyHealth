# -*- coding: utf-8 -*-
"""MIMIC_SBDH_BioClinicalBERT_Alcohol_Use.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IHL_R468SMV0DRhUbgxM3gUUxGZKLcI6

# MIMIC-SBDH + NOTEEVENTS: Bio-ClinicalBERT Alcohol Use

This notebook:
- Loads **MIMIC-SBDH** labels
- Streams **NOTEEVENTS.csv** in chunks and then does a simple pandas join
- Builds a **binary Alcohol Use** label from `behavior_alcohol`
- Fine-tunes **Bio-ClinicalBERT** with 5-fold CV
- Runs an input-length ablation (**128 vs 64 tokens**)

## Install Dependencies
"""

!pip install -q transformers accelerate datasets scikit-learn

"""## Import Libraries"""

import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader
from torch.optim import AdamW

from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import classification_report, f1_score

from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    get_linear_schedule_with_warmup,
)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print('Device:', device)

SEED = 42
np.random.seed(SEED)
torch.manual_seed(SEED)
if device.type == 'cuda':
    torch.cuda.manual_seed_all(SEED)

"""## Mount Google Drive"""

from google.colab import drive
drive.mount('/content/drive')

"""## Load MIMIC-SBDH and Prepare IDs"""

SBDH_PATH       = "/content/drive/MyDrive/Colab Notebooks/MIMIC-SBDH.csv"
NOTEEVENTS_PATH = "/content/drive/MyDrive/Colab Notebooks/NOTEEVENTS.csv"

df_sbdh = pd.read_csv(SBDH_PATH)
print("MIMIC-SBDH shape:", df_sbdh.shape)
df_sbdh.head()

df_sbdh['row_id'] = df_sbdh['row_id'].astype(int)
target_ids = set(df_sbdh['row_id'].unique())
print("Number of unique row_id in SBDH:", len(target_ids))

"""## Stream NOTEEVENTS in Chunks and Then Simple Join

We only read `ROW_ID` and `TEXT`, filter rows whose `ROW_ID` is in `target_ids`,
then concatenate and do a normal pandas merge.
"""

import re
import numpy as np

def extract_social_history(text: str):
    """
    Extract the 'Social History:' section from a discharge summary TEXT.
    Returns the section text (without the heading) or np.nan if not found.
    """
    if not isinstance(text, str):
        return np.nan

    m = re.search(
        r"social history\s*:(.*?)(?:\n[A-Z][A-Za-z /]+:|$)",
        text,
        flags=re.IGNORECASE | re.DOTALL,
    )
    if m:
        return m.group(1).strip()
    else:
        return np.nan

usecols = ['ROW_ID', 'TEXT']
chunksize = 100000
filtered_chunks = []

for i, chunk in enumerate(pd.read_csv(
    NOTEEVENTS_PATH,
    usecols=usecols,
    chunksize=chunksize,
    low_memory=False,
)):
    print(f"Processing chunk {i+1}...")

    chunk['ROW_ID'] = chunk['ROW_ID'].astype(int)

    mask_ids = chunk['ROW_ID'].isin(target_ids)
    chunk = chunk[mask_ids]
    if chunk.empty:
        continue

    chunk['TEXT'] = chunk['TEXT'].apply(extract_social_history)

    chunk = chunk.dropna(subset=['TEXT'])

    if not chunk.empty:
        filtered_chunks.append(chunk)

notes_small = pd.concat(filtered_chunks, ignore_index=True)
print("Filtered notes_small shape:", notes_small.shape)
notes_small.head()

"""## Simple pandas Join: SBDH + NOTEEVENTS"""

notes_small['ROW_ID'] = notes_small['ROW_ID'].astype(int)

df_merged = df_sbdh.merge(
    notes_small,
    left_on='row_id',
    right_on='ROW_ID',
    how='inner',
)

print("Merged shape:", df_merged.shape)
df_merged[['row_id', 'ROW_ID', 'TEXT', 'behavior_alcohol']].head()

"""## Build Alcohol Use Labels and Modeling DataFrame"""

df_merged = df_merged.rename(columns={'TEXT': 'note_text'})

TEXT_COL_RAW = 'note_text'
ALC_COL_RAW  = 'behavior_alcohol'  # original 0–4 from MIMIC-SBDH

# Keep original 0–4 labels for 5-class classification
df_model = df_merged[[TEXT_COL_RAW, ALC_COL_RAW]].dropna().copy()
df_model['behavior_alcohol'] = df_model[ALC_COL_RAW].astype(int)

print("5-class label distribution:")
print(df_model['behavior_alcohol'].value_counts())

"""## Tokenizer & Dataset Class"""

pretrained_model_name = 'emilyalsentzer/Bio_ClinicalBERT'
tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)

class NotesDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_len=128):
        self.texts = list(texts)
        self.labels = list(labels)
        self.tokenizer = tokenizer
        self.max_len = max_len

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        enc = self.tokenizer(
            self.texts[idx],
            truncation=True,
            padding='max_length',
            max_length=self.max_len,
            return_tensors='pt',
        )
        item = {k: v.squeeze(0) for k, v in enc.items()}
        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)
        return item

"""## Upsampling to Handle Class Imbalance"""

def make_upsampled_df(df, label_col):
    counts = df[label_col].value_counts()
    max_n = counts.max()
    pieces = []
    for cls, n in counts.items():
        sub = df[df[label_col] == cls]
        if n < max_n:
            extra = sub.sample(max_n - n, replace=True, random_state=42)
            sub = pd.concat([sub, extra], axis=0)
        pieces.append(sub)
    out = pd.concat(pieces, axis=0).sample(frac=1.0, random_state=42).reset_index(drop=True)
    return out

"""## Train One Fold (Bio-ClinicalBERT)"""

def train_one_fold(
    train_df,
    val_df,
    fold_idx,
    num_labels=5,
    epochs=3,
    batch_size=8,
    lr=5e-5,
    max_len=128,
):
    # label_col = 'alcohol_use_bin'
    label_col = 'behavior_alcohol'
    num_labels = 5

    train_df = make_upsampled_df(train_df, label_col)

    train_ds = NotesDataset(train_df[TEXT_COL_RAW], train_df[label_col], tokenizer, max_len=max_len)
    val_ds   = NotesDataset(val_df[TEXT_COL_RAW],   val_df[label_col],   tokenizer, max_len=max_len)

    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)
    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)

    model = AutoModelForSequenceClassification.from_pretrained(
        pretrained_model_name,
        num_labels=num_labels,
    )
    model.to(device)

    optimizer = AdamW(model.parameters(), lr=lr)

    total_steps = len(train_loader) * epochs
    scheduler = get_linear_schedule_with_warmup(
        optimizer,
        num_warmup_steps=int(0.1 * total_steps) if total_steps > 0 else 0,
        num_training_steps=total_steps if total_steps > 0 else 1,
    )

    def run_epoch(loader, train=False):
        if train:
            model.train()
        else:
            model.eval()

        total_loss = 0.0
        all_y = []
        all_pred = []

        for batch in loader:
            batch = {k: v.to(device) for k, v in batch.items()}
            labels = batch['labels']

            optimizer.zero_grad()

            with torch.set_grad_enabled(train):
                out = model(**batch)
                loss = out.loss
                logits = out.logits

                if train:
                    loss.backward()
                    optimizer.step()
                    if total_steps > 0:
                        scheduler.step()

            total_loss += loss.item() * labels.size(0)
            preds = torch.argmax(logits, dim=-1)
            all_y.extend(labels.detach().cpu().numpy().tolist())
            all_pred.extend(preds.detach().cpu().numpy().tolist())

        avg_loss = total_loss / len(loader.dataset)
        return avg_loss, np.array(all_y), np.array(all_pred)

    best_val_f1 = -1.0
    best_state = None

    for epoch in range(1, epochs + 1):
        train_loss, _, _ = run_epoch(train_loader, train=True)
        val_loss, y_true, y_pred = run_epoch(val_loader, train=False)

        macro_f1 = f1_score(y_true, y_pred, average='macro')
        print(
            f"[Fold {fold_idx}] Epoch {epoch}/{epochs} "
            f"train_loss={train_loss:.4f} val_loss={val_loss:.4f} macro_f1={macro_f1:.4f}"
        )

        f1_per_class = f1_score(y_true, y_pred, average=None)
        print("Per-class F1:", f1_per_class)

        if macro_f1 > best_val_f1:
            best_val_f1 = macro_f1
            best_state = {
                'model_state_dict': model.state_dict(),
                'y_true': y_true,
                'y_pred': y_pred,
            }

            global last_trained_model
            last_trained_model = model

    return best_val_f1, best_state

"""## Cross-Validation Wrapper"""

def run_cv_experiment(df_model, max_len=128, num_labels=2, epochs=3, batch_size=8, lr=5e-5):
    label_col = 'behavior_alcohol'
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

    fold_macro_f1 = []

    for fold, (train_idx, val_idx) in enumerate(skf.split(df_model[TEXT_COL_RAW], df_model[label_col]), start=1):
        print('=' * 70)
        print(f'Fold {fold} | max_len={max_len}')
        train_df = df_model.iloc[train_idx].reset_index(drop=True)
        val_df   = df_model.iloc[val_idx].reset_index(drop=True)

        best_f1, best_state = train_one_fold(
            train_df,
            val_df,
            fold_idx=fold,
            num_labels=5,
            epochs=epochs,
            batch_size=batch_size,
            lr=lr,
            max_len=max_len,
        )
        fold_macro_f1.append(best_f1)

        y_true = best_state['y_true']
        y_pred = best_state['y_pred']
        print(f"\n[Fold {fold}] Best-epoch classification report:")
        print(classification_report(y_true, y_pred, digits=3))
        print('=' * 70)

    print("\n==== 5-fold CV summary (macro-F1) ====")
    print("Fold macro-F1:", [f"{x:.3f}" for x in fold_macro_f1])
    print("Mean macro-F1: {:.3f} ± {:.3f}".format(np.mean(fold_macro_f1), np.std(fold_macro_f1)))

    return fold_macro_f1

"""# Run Experiments

## Baseline: max_len = 128
"""

scores_128 = run_cv_experiment(
    df_model,
    max_len=128,
    num_labels=5,
    epochs=3, # 50 was used in paper
    batch_size=8,
    lr=5e-5,
)

"""## Ablation: max_len = 64"""

scores_64 = run_cv_experiment(
    df_model,
    max_len=64,
    num_labels=5,
    epochs=3, # 50 was used in paper
    batch_size=8,
    lr=5e-5,
)

"""## Inference Tests"""

import torch
import torch.nn.functional as F

model = last_trained_model
model.eval()
model.to(device)

id2label = {
    0: "0 = None / Not mentioned",
    1: "1 = Negative",
    2: "2 = Positive",
    3: "3 = Potential",
    4: "4 = N/A / Uncertain",
}

def predict_alcohol_use_5class(
    text,
    threshold_any=0.6,
    max_len=128,
):
    """
    Run 5-class Bio-ClinicalBERT on a single note string.
    Returns:
      - predicted_label_id (int)
      - predicted_label_name (str)
      - prob_dict (dict: label_name -> probability)
      - any_alcohol_flag (bool, based on Positive+Potential >= threshold_any)
      - any_alcohol_prob (float)
    """
    enc = tokenizer(
        text,
        truncation=True,
        padding="max_length",
        max_length=max_len,
        return_tensors="pt",
    )
    enc = {k: v.to(device) for k, v in enc.items()}

    with torch.no_grad():
        logits = model(**enc).logits
        probs = F.softmax(logits, dim=-1)

    probs = probs.squeeze(0).cpu().numpy()

    pred_id = int(probs.argmax())
    pred_name = id2label.get(pred_id, str(pred_id))

    prob_dict = {id2label[i]: float(probs[i]) for i in range(len(probs))}

    p_pos = float(probs[2])
    p_pot = float(probs[3])
    p_any = p_pos + p_pot
    any_flag = p_any >= threshold_any

    return pred_id, pred_name, prob_dict, any_flag, p_any

test_texts = [
    "Patient denies any alcohol use. No drinking reported.",
    "Patient reports drinking beer daily for several years.",
    "Alcohol use unclear. Mentions occasional social drinks.",
    "No history of alcohol consumption noted.",
]

print("Running 5-class Bio-ClinicalBERT alcohol use predictions...\n")
for i, txt in enumerate(test_texts, start=1):
    pred_id, pred_name, prob_dict, any_flag, p_any = predict_alcohol_use_5class(
        txt,
        threshold_any=0.6,
        max_len=128,
    )
    print(f"Example {i}:")
    print("  Text:", txt)
    print("  Predicted 5-class label:", pred_name)
    print("  P(any alcohol use) = {:.3f} | flag = {}".format(p_any, any_flag))
    print("  Full probs:", prob_dict)
    print()